{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jgzuke/anaconda3/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import xgboost as xgb\n",
    "from sklearn import preprocessing, model_selection\n",
    "from sklearn.metrics import log_loss\n",
    "import string\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.feature_extraction.text import  CountVectorizer\n",
    "from scipy.stats import boxcox\n",
    "from scipy import stats\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "processed_train = pd.read_json('data/train.json')\n",
    "y_train = pd.read_json('data/train_interest.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fpreproc_leaky_dataframe(dtrain, dtest):\n",
    "    train, test = dtrain.data, dtest.data\n",
    "    ntrain = train.shape[0]\n",
    "    train_test = pd.concat((train, test), axis=0).reset_index(drop=True)\n",
    "    y_train = dtrain.labels\n",
    "    \n",
    "    # average listing worth\n",
    "    average_listing_worth = 0 #sum(average_interest) / len(average_interest)\n",
    "    average_low_frac = sum(y_train.values == 2)[0] * 1.0 / len(y_train)\n",
    "    average_med_frac = sum(y_train.values == 1)[0] * 1.0 / len(y_train)\n",
    "    average_high_frac = sum(y_train.values == 0)[0] * 1.0 / len(y_train)\n",
    "    average_for_counting_strategy = [average_listing_worth, average_low_frac, average_med_frac, average_high_frac]\n",
    "        \n",
    "    # add manager worths, building worths, street worths\n",
    "    divisions = ['manager_id', 'building_id', 'display_address', 'BoroCode', 'NTACode']\n",
    "    new_col_roots = ['manager', 'building', 'address', 'boro', 'nta']\n",
    "    for division, new_col_root in zip(divisions, new_col_roots):\n",
    "        division_ids = np.unique(train[division])\n",
    "        division_worths = {}\n",
    "        for division_id in division_ids:            \n",
    "            interests = y_train[train[division] == division_id].apply(lambda x: 2 - x)\n",
    "            if len(interests) > 0:\n",
    "                worth = sum(interests.values)[0] * 1.0 / len(interests)\n",
    "                low_frac = sum(interests.values == 0)[0] * 1.0 / len(interests)\n",
    "                med_frac = sum(interests.values == 1)[0] * 1.0 / len(interests)\n",
    "                high_frac = sum(interests.values == 2)[0] * 1.0 / len(interests)\n",
    "                division_worths[division_id] = [worth, low_frac, med_frac, high_frac]\n",
    "        for i, counting_strategy in enumerate(['worths', 'low_frac', 'med_frac', 'high_frac']):\n",
    "            train_test['{0}_{1}'.format(new_col_root, counting_strategy)] = train_test[division].apply(lambda x: division_worths[x][i] if x in division_worths else average_for_counting_strategy[i])\n",
    "        \n",
    "    \n",
    "    # add price by area\n",
    "    lat_long_price = train_test[['latitude', 'longitude', 'price_per_bedroom']]\n",
    "    remove_outliers = (np.abs(stats.zscore(lat_long_price)) < 0.15).all(axis=1)\n",
    "    lat_long_price = lat_long_price[remove_outliers]\n",
    "    lat_max, lat_min = max(lat_long_price.latitude), min(lat_long_price.latitude)\n",
    "    long_max, long_min = max(lat_long_price.longitude), min(lat_long_price.longitude)\n",
    "    lat_scale, long_scale = lat_max - lat_min, long_max - long_min\n",
    "    costs = np.zeros((100,100))\n",
    "    num_listings = np.zeros((100,100))\n",
    "    for lat, long, price_per_bedroom in lat_long_price.values:\n",
    "        scaled_lat, scaled_long = int((lat - lat_min) * 99 / lat_scale), int((long - long_min) * 99 / long_scale)\n",
    "        costs[scaled_lat][scaled_long] += price_per_bedroom\n",
    "        num_listings[scaled_lat][scaled_long] += 1\n",
    "\n",
    "    price_by_area = []\n",
    "    for lat, long, price_per_bedroom in train_test[['latitude', 'longitude', 'price_per_bedroom']].values:\n",
    "        scaled_lat, scaled_long = int((lat - lat_min) * 99 / lat_scale), int((long - long_min) * 99 / long_scale)\n",
    "        if scaled_lat < 0 or scaled_lat >= 100 or scaled_long < 0 or scaled_long >= 100:\n",
    "            price_by_area.append(1)\n",
    "        elif num_listings[scaled_lat][scaled_long] > 8:\n",
    "            price_by_area.append(price_per_bedroom / (costs[scaled_lat][scaled_long] / num_listings[scaled_lat][scaled_long]))\n",
    "        else:\n",
    "            cost = 0\n",
    "            num = 0\n",
    "            for i in range(scaled_lat - 1, scaled_lat + 2):\n",
    "                for j in range(scaled_long - 1, scaled_long + 2):\n",
    "                    if i > 0 and i < 100 and j >= 0 and j < 100:\n",
    "                        cost += costs[i][j]\n",
    "                        num += num_listings[i][j]\n",
    "            if num > 8:\n",
    "                price_by_area.append(price_per_bedroom / (cost / num))\n",
    "            else:\n",
    "                price_by_area.append(1)\n",
    "\n",
    "    train_test['price_by_area'] = price_by_area\n",
    "    \n",
    "    \n",
    "    # try adding real - predicted price\n",
    "    # Try to predict price for a listing and add real_price - expected_price as a feature\n",
    "    features_to_use = ['BoroCode', 'NTACode', 'bathrooms', 'bedrooms', 'other_address', 'building_worths', 'manager_worths']\n",
    "    feature_to_predict = 'price'\n",
    "    params = {\n",
    "        'objective': 'reg:linear',\n",
    "        'booster':'gblinear',\n",
    "        'lambda': 0,\n",
    "        'lambda_bias' : 0,\n",
    "        'alpha': 0.2\n",
    "    }\n",
    "    prices = train_test[feature_to_predict]\n",
    "    remove_outliers = np.abs(prices-prices.mean())<=(3*prices.std())\n",
    "    dtrain = xgb.DMatrix(data=train_test[remove_outliers][features_to_use], label=train_test[remove_outliers][feature_to_predict])\n",
    "\n",
    "    bst = xgb.cv(params, dtrain, 10000, 4, early_stopping_rounds=50, verbose_eval=200)\n",
    "    best_rounds = np.argmin(bst['test-rmse-mean'])\n",
    "    print (bst['test-rmse-mean'][best_rounds])\n",
    "    bst = xgb.train(params, dtrain, best_rounds)\n",
    "    dtrain = xgb.DMatrix(data=train_test[features_to_use])\n",
    "    expected_price = bst.predict(dtrain)\n",
    "    train_test['real_minus_expected_price'] = train_test[feature_to_predict] - expected_price\n",
    "    train_test['real_over_expected_price'] = train_test[feature_to_predict] / expected_price\n",
    "    \n",
    "    \n",
    "    # enumerated streets / price / price per street (/ num bedrooms) / price / price per street (/ num bedrooms + 0.1*bath)\n",
    "    reasonable_prices = train_test[np.abs(prices-prices.mean())<=(3*prices.std())]\n",
    "    for split in ['manager_id', 'building_id', 'display_address', 'BoroCode', 'NTACode']:\n",
    "        unique_labels = np.unique(reasonable_prices[split])\n",
    "        label_to_price = {}\n",
    "        label_to_interest = {}\n",
    "        for label in unique_labels:\n",
    "            listings = reasonable_prices[reasonable_prices[split] == label]\n",
    "            if len(listings) > 10:\n",
    "                label_to_price[label] = sum(listings.price_per_bedroom) / len(listings)\n",
    "                \n",
    "            interests = y_train[train[split] == label].apply(lambda x: 2 - x)\n",
    "            if len(interests) > 5:\n",
    "                label_to_interest[label] = sum(interests.values)[0] / len(interests)\n",
    "                \n",
    "        train_test['price_by_{}'.format(split)] = train_test.apply(lambda x: (x.price_per_bedroom / label_to_price[x[split]]) if x[split] in label_to_price else 1, axis=1)\n",
    "        train_test['worth_by_{}'.format(split)] = train_test[split].apply(lambda x: label_to_interest[x] if x in label_to_interest else average_listing_worth)\n",
    "    \n",
    "    # remove extra\n",
    "    train_test.drop('price', axis=1, inplace=True)\n",
    "    \n",
    "    return train_test[:ntrain], train_test[ntrain:], y_train\n",
    "\n",
    "def fpreproc_leaky(dtrain, dtest, param):\n",
    "    train, test, y_train = fpreproc_leaky_dataframe(dtrain, dtest)\n",
    "    dtrain = xgb.DMatrix(data=train, label=y_train)\n",
    "    dtest = xgb.DMatrix(data=test)\n",
    "    return dtrain, dtest, param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "current_filter = ['bc_price', 'price_per_bedroom', 'price_per_bathroom', 'price_per_bed_and_bath', 'BoroCode', 'NTACode', 'price', 'latitude', 'price_by_area', 'longitude', 'manager_worths', 'address1', 'real_over_expected_price', 'desc_words_length', 'real_minus_expected_price', 'manager_id', 'Yday', 'building_id', 'building_worths', 'desc_letters_count', 'Day', 'desc_words_count', 'hour', 'bedrooms', 'photos_count', 'features_count', 'Wday', 'sparse_nofee', 'bathrooms', 'sparse_furnished', 'sparse_laundryinbuilding', 'sparse_hardwoodfloors', 'sparse_laundryinunit', 'Month', 'sparse_catsallowed', 'sparse_exclusive', 'street', 'sparse_elevator', 'sparse_prewar', 'sparse_dogsallowed', 'sparse_reducedfee', 'avenue', 'east', 'sparse_doorman', 'sparse_dishwasher', 'other_address', 'sparse_fitnesscenter', 'sparse_privateoutdoorspace', 'sparse_commonoutdoorspace', 'sparse_outdoorspace', 'sparse_loft', 'sparse_diningroom', 'sparse_balcony', 'sparse_highspeedinternet', 'sparse_parkingspace', 'sparse_terrace', 'sparse_swimmingpool', 'west', 'sparse_roofdeck', 'sparse_actualapt', 'sparse_wheelchairaccess', 'sparse_newconstruction', 'Zero_building_id', 'sparse_simplex', 'sparse_patio', 'sparse_garden', 'sparse_multilevel', 'sparse_hardwood', 'sparse_shorttermallowed', 'south', 'sparse_stainlesssteelappliances', 'sparse_fireplace', 'sparse_highceiling', 'sparse_renovated', 'sparse_liveinsuper', 'sparse_storage', 'sparse_garage', 'sparse_dryerinunit', 'sparse_outdoorareas', 'sparse_petsok', 'sparse_lndrybldg', 'sparse_concierge', 'sparse_new', 'sparse_highceilings', 'sparse_onsitelaundry', 'sparse_centrala', 'sparse_flex3', 'sparse_photos', 'sparse_view', 'sparse_publicoutdoor', 'sparse_allutilitiesincluded', 'sparse_residentslounge', 'sparse_newlyrenovated', 'sparse_washerinunit', 'sparse_onsitegarage', 'sparse_assignedparkingspace', 'north', 'sparse_washer', 'sparse_light', 'sparse_dryer', 'sparse_lowrise', 'sparse_sublet', 'sparse_granitekitchen', 'sparse_elev', 'sparse_virtualdoorman', 'sparse_sundeck', 'sparse_rooftopdeck', 'sparse_wallsofwindows', 'sparse_sharesok', 'sparse_duplex', 'sparse_nopets', 'sparse_cable', 'sparse_microwave', 'sparse_wifiaccess', 'sparse_walkincloset', 'sparse_petsonapproval', 'sparse_pool', 'sparse_eatinkitchen', 'sparse_marblebath', 'sparse_live', 'sparse_sauna', 'sparse_greenbuilding', 'sparse_exposedbrick', 'sparse_largelivingroom', 'sparse_bikeroom', 'sparse_highrise', 'sparse_laundry', 'sparse_privateroofdeck', 'sparse_laundryroom', 'sparse_commonbackyard', 'sparse_privatebackyard', 'sparse_parking', 'sparse_privateparking', 'sparse_childrensplayroom', 'sparse_privatebalcony', 'sparse_indoorpool']\n",
    "\n",
    "divisions = ['manager_id', 'building_id', 'display_address', 'BoroCode', 'NTACode']\n",
    "new_col_roots = ['manager', 'building', 'address', 'boro', 'nta']\n",
    "leaky_types = ['worths', 'low_frac', 'med_frac', 'high_frac']\n",
    "leaky_worths = ['{0}_{1}'.format(new_col_root, counting_strategy) for counting_strategy in leaky_types for division, new_col_root in zip(divisions, new_col_roots)]\n",
    "\n",
    "misc_worths = ['price_by_area', 'real_minus_expected_price', 'real_over_expected_price']\n",
    "\n",
    "splits = ['manager_id', 'building_id', 'display_address', 'BoroCode', 'NTACode']\n",
    "split_worths = ['{0}_by_{1}'.format(worth_type, split) for worth_type in ['price', 'worth'] for split in splits]\n",
    "\n",
    "leaky = leaky_worths + misc_worths + misc_worths\n",
    "\n",
    "excluded = [] #'BoroCode', 'NTACode'] #, 'price_per_bedroom', 'price_per_bathroom', 'price_per_bed_and_bath']\n",
    "def filter_data_to_columns(data):\n",
    "    return data #[[col for col in current_filter if col not in leaky and col not in excluded]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FakeDMatrix:\n",
    "    def __init__(self, data, labels=None):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.num = len(data)\n",
    "\n",
    "    def num_row(self):\n",
    "        return self.num\n",
    "\n",
    "    def slice(self, rindex):\n",
    "        indices = np.zeros(self.num, dtype=np.bool)\n",
    "        for index in rindex:\n",
    "            indices[index] = True\n",
    "        return FakeDMatrix(data=self.data[indices], labels=self.labels[indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:2028.02+4.95931\ttest-rmse:2026.61+63.9387\n",
      "1577.82290675\n",
      "[0]\ttrain-rmse:2042.58+48.7314\ttest-rmse:2040.43+112.343\n",
      "1572.832428\n",
      "[0]\ttrain-rmse:2040.83+24.4325\ttest-rmse:2040.08+66.6658\n",
      "[200]\ttrain-rmse:1576.46+25.7335\ttest-rmse:1575.47+74.8311\n",
      "1575.4721375\n",
      "[0]\ttrain-mlogloss:1.09149+4.76189e-05\ttest-mlogloss:1.09179+3.25201e-05\n",
      "[200]\ttrain-mlogloss:0.590529+0.00206352\ttest-mlogloss:0.632937+0.00437172\n",
      "[400]\ttrain-mlogloss:0.509094+0.00245771\ttest-mlogloss:0.577507+0.00577111\n",
      "[600]\ttrain-mlogloss:0.473041+0.00278344\ttest-mlogloss:0.5614+0.00599762\n",
      "[800]\ttrain-mlogloss:0.448223+0.00272998\ttest-mlogloss:0.553912+0.00611605\n",
      "[1000]\ttrain-mlogloss:0.428439+0.00247294\ttest-mlogloss:0.549505+0.00607799\n",
      "[1200]\ttrain-mlogloss:0.411654+0.00215984\ttest-mlogloss:0.546701+0.00602279\n",
      "[1400]\ttrain-mlogloss:0.396108+0.00176339\ttest-mlogloss:0.544981+0.00610467\n",
      "[1600]\ttrain-mlogloss:0.382032+0.00165274\ttest-mlogloss:0.543897+0.00606365\n",
      "[1800]\ttrain-mlogloss:0.368611+0.001446\ttest-mlogloss:0.543268+0.00609572\n",
      "[2000]\ttrain-mlogloss:0.355869+0.00141072\ttest-mlogloss:0.542751+0.00609818\n",
      "[2200]\ttrain-mlogloss:0.343891+0.00150263\ttest-mlogloss:0.542609+0.00612448\n",
      "0.542595333333\n",
      "2163\n",
      "CPU times: user 2h 15min 35s, sys: 3min 43s, total: 2h 19min 19s\n",
      "Wall time: 46min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time    \n",
    "SEED = 777\n",
    "NFOLDS = 3\n",
    "y_map = {'low': 2, 'medium': 1, 'high': 0}\n",
    "\n",
    "params = {\n",
    "    'eta':.01,\n",
    "    'colsample_bytree':.8,\n",
    "    'subsample':.8,\n",
    "    'seed':0,\n",
    "    'nthread':16,\n",
    "    'objective':'multi:softprob',\n",
    "    'eval_metric':'mlogloss',\n",
    "    'num_class':3,\n",
    "    'silent':1\n",
    "}\n",
    "\n",
    "processed_train = filter_data_to_columns(pd.read_json('data/train.json'))\n",
    "y_train = pd.read_json('data/train_interest.json')\n",
    "\n",
    "dtrain = FakeDMatrix(data=processed_train, labels=y_train)\n",
    "processed_train = None\n",
    "y_train = None\n",
    "\n",
    "bst = xgb.cv(params, dtrain, 10000, NFOLDS, early_stopping_rounds=50, verbose_eval=200, fpreproc=fpreproc_leaky)\n",
    "best_rounds = np.argmin(bst['test-mlogloss-mean'])\n",
    "print (bst['test-mlogloss-mean'][best_rounds])\n",
    "print (best_rounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 0.548561666667 for all features (lb 0.54993)\n",
    "- 0.542629666667 for all features after fixing from all worths being 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run To Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:2001.04+15.3439\ttest-rmse:1999.82+26.0661\n",
      "1772.45883175\n",
      "[('bc_price', 16597), ('manager_worths', 14684), ('price_by_NTACode', 13343), ('latitude', 12299), ('longitude', 12051), ('desc_words_length', 11477), ('manager_id', 11136), ('price_by_address1', 11125), ('Yday', 10884), ('address1', 10458), ('building_worths', 10298), ('building_id', 10142), ('desc_letters_count', 9832), ('real_minus_expected_price', 9815), ('price_by_area', 9742), ('real_over_expected_price', 9374), ('Day', 9066), ('worth_by_address1', 8782), ('hour', 7722), ('price_per_bathroom', 7590), ('desc_words_count', 7481), ('price_per_bed_and_bath', 7387), ('worth_by_NTACode', 6993), ('photos_count', 6730), ('NTACode', 6324), ('price_by_BoroCode', 6098), ('features_count', 5668), ('Wday', 4445), ('price_per_bedroom', 3903), ('sparse_nofee', 3056), ('bedrooms', 2833), ('sparse_furnished', 1865), ('bathrooms', 1702), ('sparse_laundryinbuilding', 1425), ('sparse_hardwoodfloors', 1132), ('sparse_laundryinunit', 1088), ('Month', 1006), ('sparse_exclusive', 771), ('sparse_dogsallowed', 770), ('BoroCode', 749), ('sparse_catsallowed', 718), ('sparse_prewar', 663), ('sparse_privateoutdoorspace', 634), ('sparse_reducedfee', 631), ('avenue', 595), ('street', 569), ('other_address', 553), ('sparse_commonoutdoorspace', 545), ('Zero_building_id', 534), ('sparse_elevator', 533), ('east', 524), ('sparse_doorman', 510), ('sparse_parkingspace', 506), ('sparse_dishwasher', 500), ('sparse_highspeedinternet', 476), ('sparse_terrace', 424), ('sparse_fitnesscenter', 423), ('sparse_loft', 413), ('sparse_outdoorspace', 406), ('sparse_actualapt', 399), ('sparse_roofdeck', 359), ('sparse_balcony', 346), ('sparse_diningroom', 318), ('sparse_simplex', 292), ('sparse_swimmingpool', 283), ('sparse_shorttermallowed', 263), ('sparse_wheelchairaccess', 248), ('west', 245), ('sparse_newconstruction', 238), ('sparse_garden', 231), ('sparse_multilevel', 201), ('sparse_patio', 199), ('sparse_hardwood', 198), ('worth_by_BoroCode', 179), ('sparse_fireplace', 168), ('sparse_highceiling', 159), ('sparse_petsok', 154), ('sparse_dryerinunit', 153), ('sparse_stainlesssteelappliances', 148), ('sparse_garage', 119), ('south', 118), ('sparse_storage', 118), ('sparse_outdoorareas', 117), ('sparse_lndrybldg', 113), ('sparse_liveinsuper', 110), ('sparse_new', 103), ('sparse_renovated', 99), ('sparse_photos', 88), ('sparse_highceilings', 79), ('sparse_onsitelaundry', 79), ('sparse_view', 78), ('sparse_flex3', 67), ('sparse_centrala', 66), ('sparse_concierge', 64), ('sparse_residentslounge', 63), ('sparse_assignedparkingspace', 62), ('sparse_allutilitiesincluded', 58), ('sparse_onsitegarage', 53), ('north', 46), ('sparse_lowrise', 44), ('sparse_washerinunit', 44), ('sparse_granitekitchen', 41), ('sparse_dryer', 41), ('sparse_publicoutdoor', 40), ('sparse_washer', 40), ('sparse_newlyrenovated', 38), ('sparse_cable', 37), ('sparse_wifiaccess', 34), ('sparse_light', 34), ('sparse_live', 33), ('sparse_virtualdoorman', 32), ('sparse_elev', 32), ('sparse_sublet', 27), ('sparse_eatinkitchen', 25), ('sparse_duplex', 24), ('sparse_microwave', 24), ('sparse_sharesok', 23), ('sparse_nopets', 21), ('sparse_rooftopdeck', 21), ('sparse_petsonapproval', 19), ('sparse_privateroofdeck', 19), ('sparse_indoorpool', 18), ('sparse_highrise', 18), ('sparse_marblebath', 17), ('sparse_greenbuilding', 15), ('sparse_largelivingroom', 15), ('sparse_bikeroom', 14), ('sparse_pool', 12), ('sparse_privatebackyard', 12), ('sparse_commonparking', 11), ('sparse_privateparking', 11), ('sparse_commonbackyard', 10), ('sparse_walkincloset', 10), ('sparse_satellitetv', 10), ('sparse_work', 10), ('sparse_parking', 10), ('sparse_liveinsuperintendent', 8), ('sparse_subway', 8), ('sparse_children', 8), ('sparse_sauna', 7), ('sparse_laundryroom', 7), ('sparse_sundeck', 6), ('sparse_laundry', 6), ('sparse_wallsofwindows', 6), ('sparse_wheelchairramp', 6), ('sparse_privatebalcony', 6), ('sparse_exposedbrick', 6), ('sparse_childrensplayroom', 5), ('sparse_valet', 5), ('sparse_postwar', 5), ('sparse_privateterrace', 4), ('sparse_buildingcommonoutdoorspace', 4), ('sparse_fitness', 4), ('sparse_conciergeservice', 3), ('sparse_marblebathroom', 3), ('sparse_gym', 3), ('sparse_lounge', 2), ('sparse_bikestorage', 2), ('sparse_gourmetkitchen', 2), ('sparse_luxurybuilding', 2), ('sparse_24', 2), ('sparse_ornateprewardetails', 2), ('sparse_skitchen', 2), ('sparse_loungeroom', 2), ('sparse_commonterrace', 2), ('sparse_healthclub', 2), ('sparse_centralac', 2), ('sparse_businesscenter', 1), ('sparse_midrise', 1), ('sparse_packageroom', 1), ('sparse_tonsofnaturallight', 1), ('sparse_courtyard', 1), ('sparse_petfriendly', 1), ('sparse_billiardsroom', 1), ('sparse_onsitesuper', 1), ('sparse_roomyclosets', 1), ('sparse_residentsgarden', 1), ('sparse_backyard', 1), ('sparse_airconditioning', 1), ('sparse_basementstorage', 1), ('sparse_commonroofdeck', 1), ('sparse_flex2', 1)]\n",
      "CPU times: user 1h 9min 54s, sys: 1min 41s, total: 1h 11min 35s\n",
      "Wall time: 25min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "processed_test = filter_data_to_columns(pd.read_json('data/test.json'))\n",
    "listing_id = pd.read_json('data/test_ids.json').values\n",
    "\n",
    "dtest = FakeDMatrix(data=processed_test)\n",
    "processed_test = None\n",
    "\n",
    "dtrain_final, dtest_final, _ = fpreproc_leaky(dtrain, dtest, None)\n",
    "dtrain = None\n",
    "dtest = None\n",
    "\n",
    "bst = xgb.train(params, dtrain_final, best_rounds)\n",
    "dtrain_final = None\n",
    "\n",
    "preds = bst.predict(dtest_final)\n",
    "# save for column names\n",
    "#dtest_final = None\n",
    "\n",
    "preds = pd.DataFrame(preds)\n",
    "preds.columns = ['high', 'medium', 'low']\n",
    "preds['listing_id'] = listing_id\n",
    "preds.to_csv('data/my_preds.csv', index=None)\n",
    "\n",
    "importance = bst.get_fscore()\n",
    "feature_importance = [(feature, (importance[feature])) for feature in importance]\n",
    "print (sorted(feature_importance, key=lambda x: -x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0488940684429542"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#best_preds = pd.read_csv('data/my_best_preds.csv')\n",
    "#truths = np.argmax(best_preds[['high', 'medium', 'low']].values, axis=1)\n",
    "#should be < 0.5 for a good submission\n",
    "#log_loss(truths, preds[['high', 'medium', 'low']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add leaky for CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "processed_train = filter_data_to_columns(pd.read_json('data/train.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:1996.44+29.3243\ttest-rmse:1994.74+70.2588\n",
      "1564.99108875\n",
      "[0]\ttrain-rmse:1985.17+56.4164\ttest-rmse:1984.05+82.6503\n",
      "1562.24496475\n",
      "[0]\ttrain-rmse:1962.5+25.1623\ttest-rmse:1961.23+77.2626\n",
      "1563.91204825\n",
      "[0]\ttrain-rmse:1971.34+28.5286\ttest-rmse:1968.32+118.005\n",
      "[200]\ttrain-rmse:1566.52+30.1219\ttest-rmse:1564.89+93.2827\n",
      "1564.8934325\n",
      "[0]\ttrain-rmse:2008.62+44.7508\ttest-rmse:2004.42+126.164\n",
      "1564.9379275\n"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "for column in leaky:\n",
    "    processed_train[column] = 0\n",
    "folds = 5\n",
    "full_length = len(processed_train)\n",
    "entries = int(full_length / folds)\n",
    "full_index = processed_train.index\n",
    "fold_indices = []\n",
    "fold_indices_keep = []\n",
    "fold_indices_throw = []\n",
    "for i in range(folds):\n",
    "    indices = random.sample(list(full_index), entries)\n",
    "    fold_indices.append(indices)\n",
    "    full_index = full_index.drop(indices)\n",
    "\n",
    "    full_index_keep = np.zeros((full_length), dtype=np.bool)\n",
    "    full_index_throw = np.ones((full_length), dtype=np.bool)\n",
    "    for j in fold_indices[i]:\n",
    "        full_index_keep[j] = True\n",
    "        full_index_throw[j] = False\n",
    "    fold_indices_throw.append(full_index_throw)\n",
    "    fold_indices_keep.append(full_index_keep)\n",
    "    \n",
    "    dtrain = FakeDMatrix(data=processed_train[full_index_throw], labels=y_train[full_index_throw])\n",
    "    dtest = FakeDMatrix(data=processed_train[full_index_keep])\n",
    "    _, fold_with_leaky, _ = fpreproc_leaky_dataframe(dtrain, dtest)\n",
    "    processed_train.loc[sorted(indices), leaky] = fold_with_leaky[leaky].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BoroCode',\n",
       " 'Day',\n",
       " 'Month',\n",
       " 'NTACode',\n",
       " 'Wday',\n",
       " 'Yday',\n",
       " 'Zero_building_id',\n",
       " 'Zero_manager_id',\n",
       " 'avenue',\n",
       " 'bathrooms',\n",
       " 'bc_price',\n",
       " 'bedrooms',\n",
       " 'building_id',\n",
       " 'desc_letters_count',\n",
       " 'desc_words_count',\n",
       " 'desc_words_length',\n",
       " 'display_address',\n",
       " 'east',\n",
       " 'features_count',\n",
       " 'hour',\n",
       " 'latitude',\n",
       " 'longitude',\n",
       " 'manager_id',\n",
       " 'north',\n",
       " 'other_address',\n",
       " 'photos_count',\n",
       " 'price',\n",
       " 'price_per_bathroom',\n",
       " 'price_per_bed_and_bath',\n",
       " 'price_per_bedroom',\n",
       " 'south',\n",
       " 'sparse_24',\n",
       " 'sparse_2fullbaths',\n",
       " 'sparse_actualapt',\n",
       " 'sparse_airconditioning',\n",
       " 'sparse_allutilitiesincluded',\n",
       " 'sparse_assignedparkingspace',\n",
       " 'sparse_attendedlobby',\n",
       " 'sparse_backyard',\n",
       " 'sparse_balconies',\n",
       " 'sparse_balcony',\n",
       " 'sparse_basementstorage',\n",
       " 'sparse_bikeroom',\n",
       " 'sparse_bikestorage',\n",
       " 'sparse_billiardsroom',\n",
       " 'sparse_brownstone',\n",
       " 'sparse_buildingcommonoutdoorspace',\n",
       " 'sparse_businesscenter',\n",
       " 'sparse_cable',\n",
       " 'sparse_catsallowed',\n",
       " 'sparse_centrala',\n",
       " 'sparse_centralac',\n",
       " 'sparse_centralair',\n",
       " 'sparse_chef',\n",
       " 'sparse_chefskitchen',\n",
       " 'sparse_children',\n",
       " 'sparse_childrensplayroom',\n",
       " 'sparse_cityview',\n",
       " 'sparse_commonbackyard',\n",
       " 'sparse_commongarden',\n",
       " 'sparse_commonoutdoorspace',\n",
       " 'sparse_commonparking',\n",
       " 'sparse_commonroofdeck',\n",
       " 'sparse_commonterrace',\n",
       " 'sparse_communityrecreationfacilities',\n",
       " 'sparse_concierge',\n",
       " 'sparse_conciergeservice',\n",
       " 'sparse_condofinishes',\n",
       " 'sparse_cook',\n",
       " 'sparse_courtyard',\n",
       " 'sparse_deck',\n",
       " 'sparse_decorativefireplace',\n",
       " 'sparse_diningroom',\n",
       " 'sparse_dishwasher',\n",
       " 'sparse_dogsallowed',\n",
       " 'sparse_doorman',\n",
       " 'sparse_drycleaningservice',\n",
       " 'sparse_dryer',\n",
       " 'sparse_dryerinbuilding',\n",
       " 'sparse_dryerinunit',\n",
       " 'sparse_duplex',\n",
       " 'sparse_eatinkitchen',\n",
       " 'sparse_elev',\n",
       " 'sparse_elevator',\n",
       " 'sparse_elevbldg',\n",
       " 'sparse_exclusive',\n",
       " 'sparse_exposedbrick',\n",
       " 'sparse_fireplace',\n",
       " 'sparse_fireplaces',\n",
       " 'sparse_fitness',\n",
       " 'sparse_fitnesscenter',\n",
       " 'sparse_flex2',\n",
       " 'sparse_flex3',\n",
       " 'sparse_ftdoorman',\n",
       " 'sparse_fullservicegarage',\n",
       " 'sparse_fulltimedoorman',\n",
       " 'sparse_furnished',\n",
       " 'sparse_garage',\n",
       " 'sparse_garden',\n",
       " 'sparse_gourmetkitchen',\n",
       " 'sparse_granitecountertops',\n",
       " 'sparse_granitekitchen',\n",
       " 'sparse_greenbuilding',\n",
       " 'sparse_guarantorsaccepted',\n",
       " 'sparse_gutrenovated',\n",
       " 'sparse_gym',\n",
       " 'sparse_gyminbuilding',\n",
       " 'sparse_hardwood',\n",
       " 'sparse_hardwoodfloors',\n",
       " 'sparse_healthclub',\n",
       " 'sparse_highceiling',\n",
       " 'sparse_highceilings',\n",
       " 'sparse_highrise',\n",
       " 'sparse_highspeedinternet',\n",
       " 'sparse_hirise',\n",
       " 'sparse_housekeeping',\n",
       " 'sparse_indoorpool',\n",
       " 'sparse_inunitwasher',\n",
       " 'sparse_largelivingroom',\n",
       " 'sparse_laundry',\n",
       " 'sparse_laundryinbuilding',\n",
       " 'sparse_laundryinunit',\n",
       " 'sparse_laundryonfloor',\n",
       " 'sparse_laundryroom',\n",
       " 'sparse_light',\n",
       " 'sparse_live',\n",
       " 'sparse_liveinsuper',\n",
       " 'sparse_liveinsuperintendent',\n",
       " 'sparse_lndrybldg',\n",
       " 'sparse_loft',\n",
       " 'sparse_lounge',\n",
       " 'sparse_loungeroom',\n",
       " 'sparse_lowrise',\n",
       " 'sparse_luxurybuilding',\n",
       " 'sparse_mailroom',\n",
       " 'sparse_marblebath',\n",
       " 'sparse_marblebathroom',\n",
       " 'sparse_microwave',\n",
       " 'sparse_midrise',\n",
       " 'sparse_mrcleanapproved',\n",
       " 'sparse_multilevel',\n",
       " 'sparse_new',\n",
       " 'sparse_newconstruction',\n",
       " 'sparse_newlyrenovated',\n",
       " 'sparse_nofee',\n",
       " 'sparse_nopets',\n",
       " 'sparse_nursery',\n",
       " 'sparse_onsitegarage',\n",
       " 'sparse_onsitelaundry',\n",
       " 'sparse_onsiteparking',\n",
       " 'sparse_onsiteparkingavailable',\n",
       " 'sparse_onsiteparkinglot',\n",
       " 'sparse_onsitesuper',\n",
       " 'sparse_ornateprewardetails',\n",
       " 'sparse_outdoorareas',\n",
       " 'sparse_outdoorentertainmentspace',\n",
       " 'sparse_outdoorpool',\n",
       " 'sparse_outdoorspace',\n",
       " 'sparse_packageroom',\n",
       " 'sparse_parking',\n",
       " 'sparse_parkingspace',\n",
       " 'sparse_patio',\n",
       " 'sparse_penthouse',\n",
       " 'sparse_petfriendly',\n",
       " 'sparse_pets',\n",
       " 'sparse_petsallowed',\n",
       " 'sparse_petsok',\n",
       " 'sparse_petsonapproval',\n",
       " 'sparse_photos',\n",
       " 'sparse_playroom',\n",
       " 'sparse_pool',\n",
       " 'sparse_postwar',\n",
       " 'sparse_prewar',\n",
       " 'sparse_privatebackyard',\n",
       " 'sparse_privatebalcony',\n",
       " 'sparse_privatedeck',\n",
       " 'sparse_privatelaundryroomoneveryfloor',\n",
       " 'sparse_privateoutdoorspace',\n",
       " 'sparse_privateparking',\n",
       " 'sparse_privateroofdeck',\n",
       " 'sparse_privateterrace',\n",
       " 'sparse_publicoutdoor',\n",
       " 'sparse_reducedfee',\n",
       " 'sparse_renovated',\n",
       " 'sparse_residentsgarden',\n",
       " 'sparse_residentslounge',\n",
       " 'sparse_roofaccess',\n",
       " 'sparse_roofdeck',\n",
       " 'sparse_rooftopdeck',\n",
       " 'sparse_rooftopterrace',\n",
       " 'sparse_roomyclosets',\n",
       " 'sparse_satellitetv',\n",
       " 'sparse_sauna',\n",
       " 'sparse_screeningroom',\n",
       " 'sparse_sharedbackyard',\n",
       " 'sparse_sharesok',\n",
       " 'sparse_shorttermallowed',\n",
       " 'sparse_simplex',\n",
       " 'sparse_skitchen',\n",
       " 'sparse_skylight',\n",
       " 'sparse_splayroom',\n",
       " 'sparse_sskitchen',\n",
       " 'sparse_stainlesssteelappliances',\n",
       " 'sparse_stepstothepark',\n",
       " 'sparse_storage',\n",
       " 'sparse_storagefacilitiesavailable',\n",
       " 'sparse_storageroom',\n",
       " 'sparse_sublet',\n",
       " 'sparse_subway',\n",
       " 'sparse_sundeck',\n",
       " 'sparse_swimmingpool',\n",
       " 'sparse_tenantlounge',\n",
       " 'sparse_terrace',\n",
       " 'sparse_terraces',\n",
       " 'sparse_tonsofnaturallight',\n",
       " 'sparse_valet',\n",
       " 'sparse_valetparking',\n",
       " 'sparse_valetservices',\n",
       " 'sparse_valetservicesincludingdrycleaning',\n",
       " 'sparse_videointercom',\n",
       " 'sparse_view',\n",
       " 'sparse_virtualdoorman',\n",
       " 'sparse_walkincloset',\n",
       " 'sparse_wallsofwindows',\n",
       " 'sparse_washer',\n",
       " 'sparse_washerinunit',\n",
       " 'sparse_wheelchairaccess',\n",
       " 'sparse_wheelchairramp',\n",
       " 'sparse_wifi',\n",
       " 'sparse_wifiaccess',\n",
       " 'sparse_work',\n",
       " 'street',\n",
       " 'west',\n",
       " 'manager_worths',\n",
       " 'building_worths',\n",
       " 'address_worths',\n",
       " 'boro_worths',\n",
       " 'nta_worths',\n",
       " 'manager_low_frac',\n",
       " 'building_low_frac',\n",
       " 'address_low_frac',\n",
       " 'boro_low_frac',\n",
       " 'nta_low_frac',\n",
       " 'manager_med_frac',\n",
       " 'building_med_frac',\n",
       " 'address_med_frac',\n",
       " 'boro_med_frac',\n",
       " 'nta_med_frac',\n",
       " 'manager_high_frac',\n",
       " 'building_high_frac',\n",
       " 'address_high_frac',\n",
       " 'boro_high_frac',\n",
       " 'nta_high_frac',\n",
       " 'price_by_area',\n",
       " 'real_minus_expected_price',\n",
       " 'real_over_expected_price']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(processed_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "processed_train = processed_train.drop('price', axis=1)\n",
    "processed_train.to_json('data/train_with_leaky_cv.json', orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add leaky feats and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:2001.94+15.2958\ttest-rmse:2002.47+35.3504\n",
      "1772.8644105\n"
     ]
    }
   ],
   "source": [
    "processed_train = filter_data_to_columns(pd.read_json('data/train.json'))\n",
    "y_train = pd.read_json('data/train_interest.json')\n",
    "dtrain = FakeDMatrix(data=processed_train, labels=y_train)\n",
    "\n",
    "processed_test = filter_data_to_columns(pd.read_json('data/test.json'))\n",
    "listing_id = pd.read_json('data/test_ids.json').values\n",
    "dtest = FakeDMatrix(data=processed_test)\n",
    "train, test, y_train = fpreproc_leaky_dataframe(dtrain, dtest)\n",
    "train.to_json('data/train_leaky.json', orient='records')\n",
    "test.index = range(len(test))\n",
    "test.to_json('data/test_leaky.json', orient='records')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
