{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import xgboost as xgb\n",
    "from sklearn import preprocessing, model_selection\n",
    "from sklearn.metrics import log_loss\n",
    "import string\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.feature_extraction.text import  CountVectorizer\n",
    "from scipy.stats import boxcox\n",
    "from scipy import stats\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fpreproc_leaky(dtrain, dtest, param):\n",
    "    train, test = dtrain.data, dtest.data\n",
    "    ntrain = train.shape[0]\n",
    "    train_test = pd.concat((train, test), axis=0).reset_index(drop=True)\n",
    "    y_train = dtrain.labels\n",
    "    \n",
    "    # average listing worth\n",
    "    average_listing_worth = 0 #sum(average_interest) / len(average_interest)\n",
    "    \n",
    "    # add manager worths\n",
    "    manager_ids = np.unique(train.manager_id)\n",
    "    manager_worths = {}\n",
    "    for manager_id in manager_ids:\n",
    "        interests = y_train[train.manager_id == manager_id].apply(lambda x: 2 - x)\n",
    "        if len(interests) > 5:\n",
    "            manager_worths[manager_id] = sum(interests) / len(interests)\n",
    "    average_interest = y_train.apply(lambda x: 2 - x)\n",
    "    train_test['manager_worths'] = train_test['manager_id'].apply(lambda x: manager_worths[x] if x in manager_worths else average_listing_worth)\n",
    "\n",
    "    \n",
    "    # add building worths\n",
    "    building_ids = np.unique(train.building_id)\n",
    "    building_worths = {}\n",
    "    for building_id in building_ids:\n",
    "        interests = y_train[train.building_id == building_id].apply(lambda x: 2 - x)\n",
    "        if len(interests) > 5:\n",
    "            building_worths[building_id] = sum(interests) / len(interests)\n",
    "    average_interest = y_train.apply(lambda x: 2 - x)\n",
    "    train_test['building_worths'] = train_test['building_id'].apply(lambda x: building_worths[x] if x in building_worths else average_listing_worth)\n",
    "\n",
    "    \n",
    "    # add price by area\n",
    "    lat_long_price = train_test[['latitude', 'longitude', 'price_per_bedroom']]\n",
    "    remove_outliers = (np.abs(stats.zscore(lat_long_price)) < 0.15).all(axis=1)\n",
    "    lat_long_price = lat_long_price[remove_outliers]\n",
    "    lat_max, lat_min = max(lat_long_price.latitude), min(lat_long_price.latitude)\n",
    "    long_max, long_min = max(lat_long_price.longitude), min(lat_long_price.longitude)\n",
    "    lat_scale, long_scale = lat_max - lat_min, long_max - long_min\n",
    "    costs = np.zeros((100,100))\n",
    "    num_listings = np.zeros((100,100))\n",
    "    for lat, long, price_per_bedroom in lat_long_price.values:\n",
    "        scaled_lat, scaled_long = int((lat - lat_min) * 99 / lat_scale), int((long - long_min) * 99 / long_scale)\n",
    "        costs[scaled_lat][scaled_long] += price_per_bedroom\n",
    "        num_listings[scaled_lat][scaled_long] += 1\n",
    "\n",
    "    price_by_area = []\n",
    "    for lat, long, price_per_bedroom in train_test[['latitude', 'longitude', 'price_per_bedroom']].values:\n",
    "        scaled_lat, scaled_long = int((lat - lat_min) * 99 / lat_scale), int((long - long_min) * 99 / long_scale)\n",
    "        if scaled_lat < 0 or scaled_lat >= 100 or scaled_long < 0 or scaled_long >= 100:\n",
    "            price_by_area.append(1)\n",
    "        elif num_listings[scaled_lat][scaled_long] > 8:\n",
    "            price_by_area.append(price_per_bedroom / (costs[scaled_lat][scaled_long] / num_listings[scaled_lat][scaled_long]))\n",
    "        else:\n",
    "            cost = 0\n",
    "            num = 0\n",
    "            for i in range(scaled_lat - 1, scaled_lat + 2):\n",
    "                for j in range(scaled_long - 1, scaled_long + 2):\n",
    "                    if i > 0 and i < 100 and j >= 0 and j < 100:\n",
    "                        cost += costs[i][j]\n",
    "                        num += num_listings[i][j]\n",
    "            if num > 8:\n",
    "                price_by_area.append(price_per_bedroom / (cost / num))\n",
    "            else:\n",
    "                price_by_area.append(1)\n",
    "\n",
    "    train_test['price_by_area'] = price_by_area\n",
    "    \n",
    "    \n",
    "    # try adding real - predicted price\n",
    "    # Try to predict price for a listing and add real_price - expected_price as a feature\n",
    "    features_to_use = ['BoroCode', 'NTACode', 'bathrooms', 'bedrooms', 'address1', 'other_address', 'building_worths', 'manager_worths']\n",
    "    feature_to_predict = 'price'\n",
    "    params = {\n",
    "        'objective': 'reg:linear',\n",
    "        'booster':'gblinear',\n",
    "        'lambda': 0,\n",
    "        'lambda_bias' : 0,\n",
    "        'alpha': 0.2\n",
    "    }\n",
    "    prices = train_test[feature_to_predict]\n",
    "    remove_outliers = np.abs(prices-prices.mean())<=(3*prices.std())\n",
    "    dtrain = xgb.DMatrix(data=train_test[remove_outliers][features_to_use], label=train_test[remove_outliers][feature_to_predict])\n",
    "\n",
    "    bst = xgb.cv(params, dtrain, 10000, 4, early_stopping_rounds=50, verbose_eval=200)\n",
    "    best_rounds = np.argmin(bst['test-rmse-mean'])\n",
    "    print (bst['test-rmse-mean'][best_rounds])\n",
    "    bst = xgb.train(params, dtrain, best_rounds)\n",
    "    dtrain = xgb.DMatrix(data=train_test[features_to_use])\n",
    "    expected_price = bst.predict(dtrain)\n",
    "    train_test['real_minus_expected_price'] = train_test[feature_to_predict] - expected_price\n",
    "    train_test['real_over_expected_price'] = train_test[feature_to_predict] / expected_price\n",
    "    \n",
    "    \n",
    "    # enumerated streets / price / price per street (/ num bedrooms) / price / price per street (/ num bedrooms + 0.1*bath)\n",
    "    reasonable_prices = train_test[np.abs(prices-prices.mean())<=(3*prices.std())]\n",
    "    for split in ['address1', 'BoroCode', 'NTACode']:\n",
    "        unique_labels = np.unique(reasonable_prices[split])\n",
    "        label_to_price = {}\n",
    "        label_to_interest = {}\n",
    "        for label in unique_labels:\n",
    "            listings = reasonable_prices[reasonable_prices[split] == label]\n",
    "            if len(listings) > 10:\n",
    "                label_to_price[label] = sum(listings.price_per_bedroom) / len(listings)\n",
    "                \n",
    "            interests = y_train[train[split] == label].apply(lambda x: 2 - x)\n",
    "            if len(interests) > 5:\n",
    "                building_worths[building_id] = sum(interests) / len(interests)\n",
    "                \n",
    "        train_test['price_by_{}'.format(split)] = train_test.apply(lambda x: (x.price_per_bedroom / label_to_price[x[split]]) if x[split] in label_to_price else 1, axis=1)\n",
    "        train_test['worth_by_{}'.format(split)] = train_test[split].apply(lambda x: label_to_interest[x] if x in label_to_interest else average_listing_worth)\n",
    "    \n",
    "    # remove extra\n",
    "    train_test.drop('price', axis=1, inplace=True)\n",
    "    \n",
    "    dtrain = xgb.DMatrix(data=train_test[:ntrain], label=y_train)\n",
    "    dtest = xgb.DMatrix(data=train_test[ntrain:], label=dtest.labels)\n",
    "    return dtrain, dtest, param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "current_filter = ['bc_price', 'price_per_bedroom', 'price_per_bathroom', 'price_per_bed_and_bath', 'BoroCode', 'NTACode', 'price', 'latitude', 'price_by_area', 'longitude', 'manager_worths', 'address1', 'real_over_expected_price', 'desc_words_length', 'real_minus_expected_price', 'manager_id', 'Yday', 'building_id', 'building_worths', 'desc_letters_count', 'Day', 'desc_words_count', 'hour', 'bedrooms', 'photos_count', 'features_count', 'Wday', 'sparse_nofee', 'bathrooms', 'sparse_furnished', 'sparse_laundryinbuilding', 'sparse_hardwoodfloors', 'sparse_laundryinunit', 'Month', 'sparse_catsallowed', 'sparse_exclusive', 'street', 'sparse_elevator', 'sparse_prewar', 'sparse_dogsallowed', 'sparse_reducedfee', 'avenue', 'east', 'sparse_doorman', 'sparse_dishwasher', 'other_address', 'sparse_fitnesscenter', 'sparse_privateoutdoorspace', 'sparse_commonoutdoorspace', 'sparse_outdoorspace', 'sparse_loft', 'sparse_diningroom', 'sparse_balcony', 'sparse_highspeedinternet', 'sparse_parkingspace', 'sparse_terrace', 'sparse_swimmingpool', 'west', 'sparse_roofdeck', 'sparse_actualapt', 'sparse_wheelchairaccess', 'sparse_newconstruction', 'Zero_building_id', 'sparse_simplex', 'sparse_patio', 'sparse_garden', 'sparse_multilevel', 'sparse_hardwood', 'sparse_shorttermallowed', 'south', 'sparse_stainlesssteelappliances', 'sparse_fireplace', 'sparse_highceiling', 'sparse_renovated', 'sparse_liveinsuper', 'sparse_storage', 'sparse_garage', 'sparse_dryerinunit', 'sparse_outdoorareas', 'sparse_petsok', 'sparse_lndrybldg', 'sparse_concierge', 'sparse_new', 'sparse_highceilings', 'sparse_onsitelaundry', 'sparse_centrala', 'sparse_flex3', 'sparse_photos', 'sparse_view', 'sparse_publicoutdoor', 'sparse_allutilitiesincluded', 'sparse_residentslounge', 'sparse_newlyrenovated', 'sparse_washerinunit', 'sparse_onsitegarage', 'sparse_assignedparkingspace', 'north', 'sparse_washer', 'sparse_light', 'sparse_dryer', 'sparse_lowrise', 'sparse_sublet', 'sparse_granitekitchen', 'sparse_elev', 'sparse_virtualdoorman', 'sparse_sundeck', 'sparse_rooftopdeck', 'sparse_wallsofwindows', 'sparse_sharesok', 'sparse_duplex', 'sparse_nopets', 'sparse_cable', 'sparse_microwave', 'sparse_wifiaccess', 'sparse_walkincloset', 'sparse_petsonapproval', 'sparse_pool', 'sparse_eatinkitchen', 'sparse_marblebath', 'sparse_live', 'sparse_sauna', 'sparse_greenbuilding', 'sparse_exposedbrick', 'sparse_largelivingroom', 'sparse_bikeroom', 'sparse_highrise', 'sparse_laundry', 'sparse_privateroofdeck', 'sparse_laundryroom', 'sparse_commonbackyard', 'sparse_privatebackyard', 'sparse_parking', 'sparse_privateparking', 'sparse_childrensplayroom', 'sparse_privatebalcony', 'sparse_indoorpool']\n",
    "leaky = ['manager_worths', 'building_worths', 'price_by_area', 'real_minus_expected_price', 'real_over_expected_price']\n",
    "excluded = [] #'BoroCode', 'NTACode'] #, 'price_per_bedroom', 'price_per_bathroom', 'price_per_bed_and_bath']\n",
    "def filter_data_to_columns(data):\n",
    "    return data #[[col for col in current_filter if col not in leaky and col not in excluded]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:2083.23+30.0705\ttest-rmse:2083.98+39.537\n",
      "1602.2826235\n",
      "[0]\ttrain-rmse:2071.23+30.1386\ttest-rmse:2069.24+131.235\n",
      "1597.31063825\n",
      "[0]\ttrain-rmse:2070.66+27.4862\ttest-rmse:2070.23+60.2916\n",
      "1600.05746475\n",
      "[0]\ttrain-mlogloss:1.09196+4.36527e-05\ttest-mlogloss:1.09208+4.22401e-05\n",
      "[200]\ttrain-mlogloss:0.628839+0.00232108\ttest-mlogloss:0.652616+0.0045371\n",
      "[400]\ttrain-mlogloss:0.552482+0.00238481\ttest-mlogloss:0.595837+0.0058769\n",
      "[600]\ttrain-mlogloss:0.516675+0.00235895\ttest-mlogloss:0.577829+0.0061741\n",
      "[800]\ttrain-mlogloss:0.491893+0.00249106\ttest-mlogloss:0.568609+0.00615336\n",
      "[1000]\ttrain-mlogloss:0.47151+0.00250778\ttest-mlogloss:0.562713+0.00616888\n",
      "[1200]\ttrain-mlogloss:0.45351+0.00202205\ttest-mlogloss:0.558642+0.0061532\n",
      "[1400]\ttrain-mlogloss:0.437446+0.00180935\ttest-mlogloss:0.555804+0.00614963\n",
      "[1600]\ttrain-mlogloss:0.422506+0.00146847\ttest-mlogloss:0.553586+0.0061342\n",
      "[1800]\ttrain-mlogloss:0.408588+0.00108397\ttest-mlogloss:0.551995+0.00618322\n",
      "[2000]\ttrain-mlogloss:0.395405+0.000899436\ttest-mlogloss:0.550746+0.00626955\n",
      "[2200]\ttrain-mlogloss:0.383023+0.000840482\ttest-mlogloss:0.549909+0.00627165\n",
      "[2400]\ttrain-mlogloss:0.370972+0.000571652\ttest-mlogloss:0.5493+0.00632389\n",
      "[2600]\ttrain-mlogloss:0.359473+0.000641303\ttest-mlogloss:0.548846+0.00638696\n",
      "[2800]\ttrain-mlogloss:0.348571+0.000475158\ttest-mlogloss:0.548629+0.00637332\n",
      "0.548561666667\n",
      "2939\n",
      "CPU times: user 1h 51min 21s, sys: 5min, total: 1h 56min 21s\n",
      "Wall time: 37min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "class FakeDMatrix:\n",
    "    def __init__(self, data, labels=None):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.num = len(data)\n",
    "\n",
    "    def num_row(self):\n",
    "        return self.num\n",
    "\n",
    "    def slice(self, rindex):\n",
    "        indices = np.zeros(self.num, dtype=np.bool)\n",
    "        for index in rindex:\n",
    "            indices[index] = True\n",
    "        return FakeDMatrix(data=self.data[indices], labels=self.labels[indices])\n",
    "    \n",
    "SEED = 777\n",
    "NFOLDS = 3\n",
    "y_map = {'low': 2, 'medium': 1, 'high': 0}\n",
    "\n",
    "params = {\n",
    "    'eta':.01,\n",
    "    'colsample_bytree':.8,\n",
    "    'subsample':.8,\n",
    "    'seed':0,\n",
    "    'nthread':16,\n",
    "    'objective':'multi:softprob',\n",
    "    'eval_metric':'mlogloss',\n",
    "    'num_class':3,\n",
    "    'silent':1\n",
    "}\n",
    "\n",
    "processed_train = filter_data_to_columns(pd.read_json('data/train.json'))\n",
    "y_train = pd.read_json('data/train_interest.json')\n",
    "\n",
    "dtrain = FakeDMatrix(data=processed_train, labels=y_train)\n",
    "processed_train = None\n",
    "y_train = None\n",
    "\n",
    "bst = xgb.cv(params, dtrain, 10000, NFOLDS, early_stopping_rounds=50, verbose_eval=200, fpreproc=fpreproc_leaky)\n",
    "best_rounds = np.argmin(bst['test-mlogloss-mean'])\n",
    "print (bst['test-mlogloss-mean'][best_rounds])\n",
    "print (best_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 0.548561666667 for all features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run To Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:2117.09+62.7868\ttest-rmse:2121.33+83.1981\n",
      "1808.70608525\n",
      "[('manager_id', 25553), ('latitude', 20254), ('bc_price', 20116), ('desc_words_length', 18940), ('price_by_NTACode', 18351), ('longitude', 18261), ('address1', 17010), ('building_id', 16999), ('Yday', 16890), ('desc_letters_count', 15582), ('price_by_address1', 15567), ('real_over_expected_price', 14559), ('real_minus_expected_price', 13605), ('price_by_area', 13129), ('Day', 12079), ('desc_words_count', 11809), ('hour', 11576), ('NTACode', 9952), ('photos_count', 9878), ('price_per_bathroom', 9838), ('price_per_bedroom', 8838), ('features_count', 8648), ('price_by_BoroCode', 8522), ('price_per_bed_and_bath', 6906), ('Wday', 6848), ('sparse_nofee', 3752), ('bedrooms', 3254), ('bathrooms', 2483), ('sparse_furnished', 2294), ('sparse_laundryinbuilding', 2249), ('sparse_hardwoodfloors', 1930), ('sparse_laundryinunit', 1506), ('sparse_prewar', 1292), ('sparse_catsallowed', 1258), ('sparse_dogsallowed', 1187), ('sparse_reducedfee', 1085), ('sparse_dishwasher', 974), ('street', 968), ('avenue', 964), ('BoroCode', 954), ('sparse_outdoorspace', 871), ('sparse_exclusive', 866), ('east', 854), ('sparse_elevator', 848), ('other_address', 822), ('sparse_privateoutdoorspace', 816), ('sparse_doorman', 788), ('sparse_loft', 706), ('sparse_balcony', 699), ('sparse_commonoutdoorspace', 680), ('sparse_fitnesscenter', 655), ('Month', 650), ('sparse_terrace', 645), ('sparse_diningroom', 635), ('sparse_roofdeck', 610), ('sparse_actualapt', 593), ('sparse_parkingspace', 577), ('sparse_highspeedinternet', 570), ('sparse_simplex', 568), ('sparse_wheelchairaccess', 551), ('sparse_swimmingpool', 545), ('sparse_newconstruction', 528), ('west', 450), ('Zero_building_id', 448), ('sparse_patio', 433), ('sparse_hardwood', 327), ('sparse_multilevel', 293), ('sparse_highceiling', 254), ('south', 243), ('sparse_garden', 241), ('sparse_renovated', 206), ('sparse_storage', 206), ('sparse_fireplace', 195), ('sparse_stainlesssteelappliances', 178), ('sparse_outdoorareas', 178), ('sparse_shorttermallowed', 160), ('sparse_highceilings', 154), ('sparse_petsok', 152), ('sparse_washerinunit', 130), ('sparse_newlyrenovated', 129), ('sparse_liveinsuper', 128), ('sparse_photos', 128), ('sparse_publicoutdoor', 126), ('sparse_dryerinunit', 119), ('sparse_garage', 110), ('sparse_view', 108), ('sparse_concierge', 103), ('north', 96), ('sparse_onsitelaundry', 92), ('sparse_lndrybldg', 86), ('sparse_elev', 77), ('sparse_greenbuilding', 76), ('sparse_lowrise', 75), ('sparse_granitekitchen', 74), ('sparse_new', 74), ('sparse_assignedparkingspace', 70), ('sparse_walkincloset', 67), ('sparse_live', 65), ('sparse_pool', 64), ('sparse_wifiaccess', 64), ('sparse_washer', 64), ('sparse_residentslounge', 61), ('sparse_allutilitiesincluded', 58), ('sparse_largelivingroom', 54), ('sparse_onsitegarage', 53), ('sparse_sundeck', 50), ('sparse_sauna', 48), ('sparse_commonbackyard', 47), ('sparse_bikeroom', 47), ('sparse_privateroofdeck', 45), ('sparse_eatinkitchen', 45), ('sparse_flex3', 44), ('sparse_cable', 43), ('sparse_virtualdoorman', 42), ('sparse_microwave', 42), ('sparse_petsonapproval', 40), ('sparse_wallsofwindows', 39), ('sparse_dryer', 39), ('sparse_exposedbrick', 38), ('sparse_light', 38), ('sparse_sublet', 36), ('sparse_indoorpool', 36), ('sparse_centrala', 34), ('sparse_duplex', 31), ('sparse_parking', 30), ('sparse_laundryroom', 27), ('sparse_highrise', 26), ('sparse_nopets', 23), ('sparse_privateparking', 20), ('sparse_marblebath', 17), ('sparse_privatebalcony', 16), ('sparse_privatebackyard', 16), ('sparse_laundry', 16), ('sparse_rooftopdeck', 14), ('sparse_childrensplayroom', 10), ('sparse_sharesok', 8)]\n",
      "CPU times: user 58min 7s, sys: 1min 44s, total: 59min 51s\n",
      "Wall time: 18min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "processed_test = filter_data_to_columns(pd.read_json('data/test.json'))\n",
    "listing_id = pd.read_json('data/test_ids.json').values\n",
    "\n",
    "dtest = FakeDMatrix(data=processed_test)\n",
    "processed_test = None\n",
    "\n",
    "dtrain_final, dtest_final, _ = fpreproc_leaky(dtrain, dtest, None)\n",
    "dtrain = None\n",
    "dtest = None\n",
    "\n",
    "bst = xgb.train(params, dtrain_final, best_rounds)\n",
    "dtrain_final = None\n",
    "\n",
    "preds = bst.predict(dtest_final)\n",
    "# save for column names\n",
    "#dtest_final = None\n",
    "\n",
    "preds = pd.DataFrame(preds)\n",
    "preds.columns = ['high', 'medium', 'low']\n",
    "preds['listing_id'] = listing_id\n",
    "preds.to_csv('data/my_preds.csv', index=None)\n",
    "\n",
    "importance = bst.get_fscore()\n",
    "feature_importance = [(feature, (importance[feature])) for feature in importance]\n",
    "print (sorted(feature_importance, key=lambda x: -x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9934837700772069"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#best_preds = pd.read_csv('data/my_best_preds.csv')\n",
    "#truths = np.argmax(best_preds[['high', 'medium', 'low']].values, axis=1)\n",
    "# should be < 0.5 for a good submission\n",
    "#log_loss(truths, preds[['high', 'medium', 'low']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
