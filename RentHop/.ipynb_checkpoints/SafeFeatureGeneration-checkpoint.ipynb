{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import xgboost as xgb\n",
    "from sklearn import preprocessing, model_selection\n",
    "from sklearn.metrics import log_loss\n",
    "import string\n",
    "from sklearn.feature_extraction.text import  CountVectorizer\n",
    "from scipy.stats import boxcox\n",
    "from scipy import stats\n",
    "from scipy import sparse\n",
    "\n",
    "y_map = {'low': 2, 'medium': 1, 'high': 0}\n",
    "\n",
    "train = pd.read_json('data/backup/train.json')\n",
    "test = pd.read_json('data/backup/test.json')\n",
    "\n",
    "y_train = train['interest_level'].apply(lambda x: y_map[x]).reset_index(drop=True)\n",
    "train = train.drop(['listing_id', 'interest_level'], axis=1)\n",
    "listing_id = test.listing_id\n",
    "test = test.drop('listing_id', axis=1)\n",
    "\n",
    "y_train.to_json('data/train_interest.json', orient='records')\n",
    "listing_id.to_json('data/test_ids.json', orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ntrain = train.shape[0]\n",
    "train_test = pd.concat((train, test), axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert date to be more useable\n",
    "train_test['Date'] = pd.to_datetime(train_test['created'])\n",
    "# year is all the same\n",
    "#train_test['Year'] = train_test['Date'].dt.year\n",
    "train_test['Month'] = train_test['Date'].dt.month\n",
    "train_test['Day'] = train_test['Date'].dt.day\n",
    "train_test['Wday'] = train_test['Date'].dt.dayofweek\n",
    "train_test['Yday'] = train_test['Date'].dt.dayofyear\n",
    "train_test['hour'] = train_test['Date'].dt.hour\n",
    "train_test = train_test.drop(['Date', 'created'], axis=1)\n",
    "\n",
    "\n",
    "# check if this building id/manager id and add worths is 0\n",
    "train_test['Zero_building_id'] = train_test['building_id'].apply(lambda x: 1 if x == '0' else 0)\n",
    "train_test['Zero_manager_id'] = train_test['manager_id'].apply(lambda x: 1 if x == '0' else 0)\n",
    "\n",
    "\n",
    "# mess with description meta data\n",
    "train_test['desc'] = train_test['description']\n",
    "train_test['desc'] = train_test['desc'].apply(lambda x: x.replace('<p><a  website_redacted ', ''))\n",
    "train_test['desc'] = train_test['desc'].apply(lambda x: x.replace('!<br /><br />', ''))\n",
    "\n",
    "string.punctuation.__add__('!!')\n",
    "string.punctuation.__add__('(')\n",
    "string.punctuation.__add__(')')\n",
    "remove_punct_map = dict.fromkeys(map(ord, string.punctuation))\n",
    "\n",
    "train_test['desc'] = train_test['desc'].apply(lambda x: x.translate(remove_punct_map))\n",
    "train_test['desc_letters_count'] = train_test['description'].apply(lambda x: len(x.strip()))\n",
    "train_test['desc_words_count'] = train_test['desc'].apply(lambda x: 0 if len(x.strip()) == 0 else len(x.split(' ')))\n",
    "train_test['desc_words_length'] = (train_test['desc_letters_count'] / train_test['desc_words_count']).apply(lambda x: 0 if math.isnan(x) or math.isinf(x) else x)\n",
    "\n",
    "train_test.drop(['description', 'desc'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# address\n",
    "train_test['address1'] = train_test['display_address']\n",
    "train_test['address1'] = train_test['address1'].apply(lambda x: x.lower())\n",
    "\n",
    "address_map = {\n",
    "    'w': 'west',\n",
    "    'st.': 'street',\n",
    "    'ave': 'avenue',\n",
    "    'st': 'street',\n",
    "    'e': 'east',\n",
    "    'n': 'north',\n",
    "    's': 'south'\n",
    "}\n",
    "\n",
    "def address_map_func(s):\n",
    "    s = s.split(' ')\n",
    "    out = []\n",
    "    for x in s:\n",
    "        if x in address_map:\n",
    "            out.append(address_map[x])\n",
    "        else:\n",
    "            out.append(x)\n",
    "    return ' '.join(out)\n",
    "\n",
    "\n",
    "train_test['address1'] = train_test['address1'].apply(lambda x: x.translate(remove_punct_map))\n",
    "train_test['address1'] = train_test['address1'].apply(lambda x: address_map_func(x))\n",
    "\n",
    "new_cols = ['street', 'avenue', 'east', 'west', 'north', 'south']\n",
    "for col in new_cols:\n",
    "    train_test[col] = train_test['address1'].apply(lambda x: 1 if col in x else 0)\n",
    "\n",
    "train_test['other_address'] = train_test[new_cols].apply(lambda x: 1 if x.sum() == 0 else 0, axis=1)\n",
    "train_test.drop(['street_address', 'address1'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# features (better not to lower)\n",
    "train_test['features_count'] = train_test['features'].apply(lambda x: len(x))\n",
    "train_test['features2'] = train_test['features']\n",
    "train_test['features2'] = train_test['features2'].apply(lambda x: ' '.join([''.join(i.replace('_',' ').replace('-',' ').split(' ')) for i in x]))\n",
    "\n",
    "c_vect = CountVectorizer(stop_words='english', max_features=200, ngram_range=(1, 1))\n",
    "c_vect.fit(train_test['features2'])\n",
    "\n",
    "c_vect_sparse_1 = c_vect.transform(train_test['features2'])\n",
    "c_vect_sparse1_cols = c_vect.get_feature_names()\n",
    "train_test.drop(['features', 'features2'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# photos\n",
    "train_test['photos_count'] = train_test['photos'].apply(lambda x: len(x))\n",
    "train_test.drop(['photos'], axis=1, inplace=True)\n",
    "\n",
    "# convert ['building_id', 'manager_id', 'address1'] to enumerated labels\n",
    "categoricals = ['building_id', 'display_address', 'manager_id']\n",
    "for feat in categoricals:\n",
    "    # clump all things with one entry per section\n",
    "    counts = train_test.groupby(feat, as_index = False).size()\n",
    "    section_with_one_lot = counts[counts == 1]\n",
    "    train_test.loc[train_test[feat].isin(section_with_one_lot.keys()), feat] = \"-1\"\n",
    "    \n",
    "    # convert ['building_id', 'manager_id', 'address1'] to enumerated labels\n",
    "    encoder = preprocessing.LabelEncoder()\n",
    "    encoder.fit(list(train_test[feat].values))\n",
    "    train_test[feat] = encoder.transform(train_test[feat].ravel())\n",
    "\n",
    "# transform managers and building ids\n",
    "#train_test['manager_id'] = train_test['manager_id'].apply(lambda x: str(x))\n",
    "#train_test['manager_id'], labels = pd.factorize(train_test['manager_id'].values, sort=True)\n",
    "#train_test['building_id'] = train_test['building_id'].apply(lambda x: str(x))\n",
    "#train_test['building_id'], labels = pd.factorize(train_test['building_id'].values, sort=True)\n",
    "\n",
    "\n",
    "# transform price\n",
    "bc_price, tmp = boxcox(train_test.price)\n",
    "train_test['bc_price'] = bc_price\n",
    "\n",
    "\n",
    "# add price per bed/bath\n",
    "train_test['price_per_bedroom'] = train_test.apply(lambda x: x.price / max(1, x.bedrooms), axis=1)\n",
    "train_test['price_per_bathroom'] = train_test.apply(lambda x: x.price / max(1, x.bathrooms), axis=1)\n",
    "train_test['price_per_bed_and_bath'] = train_test.apply(lambda x: x.price / (max(1, x.bedrooms) + max(1, x.bathrooms)*0.1), axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bathrooms                 float64\n",
       "bedrooms                    int64\n",
       "building_id                 int64\n",
       "display_address             int64\n",
       "latitude                  float64\n",
       "longitude                 float64\n",
       "manager_id                  int64\n",
       "price                       int64\n",
       "Month                       int64\n",
       "Day                         int64\n",
       "Wday                        int64\n",
       "Yday                        int64\n",
       "hour                        int64\n",
       "Zero_building_id            int64\n",
       "Zero_manager_id             int64\n",
       "desc_letters_count          int64\n",
       "desc_words_count            int64\n",
       "desc_words_length         float64\n",
       "address1                   object\n",
       "street                      int64\n",
       "avenue                      int64\n",
       "east                        int64\n",
       "west                        int64\n",
       "north                       int64\n",
       "south                       int64\n",
       "other_address               int64\n",
       "features_count              int64\n",
       "photos_count                int64\n",
       "bc_price                  float64\n",
       "price_per_bedroom         float64\n",
       "price_per_bathroom        float64\n",
       "price_per_bed_and_bath    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<124011x200 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 674961 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_vect_sparse_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "no supported conversion for types: (dtype('O'), dtype('int64'))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-eb4b1e3b19d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_vect_sparse_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtocsr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/jgzuke/anaconda3/lib/python3.5/site-packages/scipy/sparse/construct.py\u001b[0m in \u001b[0;36mhstack\u001b[0;34m(blocks, format, dtype)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m     \"\"\"\n\u001b[0;32m--> 464\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jgzuke/anaconda3/lib/python3.5/site-packages/scipy/sparse/construct.py\u001b[0m in \u001b[0;36mbmat\u001b[0;34m(blocks, format, dtype)\u001b[0m\n\u001b[1;32m    595\u001b[0m     \u001b[0mnnz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnnz\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mblock_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mblk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mblock_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[0mrow_offsets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbrow_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jgzuke/anaconda3/lib/python3.5/site-packages/scipy/sparse/sputils.py\u001b[0m in \u001b[0;36mupcast\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'no supported conversion for types: %r'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: no supported conversion for types: (dtype('O'), dtype('int64'))"
     ]
    }
   ],
   "source": [
    "sparse.hstack((train_test, c_vect_sparse_1)).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add sparse\n",
    "train_test_cv1_sparse = sparse.hstack((train_test, c_vect_sparse_1)).tocsr()\n",
    "x_train = train_test_cv1_sparse[:ntrain, :]\n",
    "x_test = train_test_cv1_sparse[ntrain:, :]\n",
    "\n",
    "# add feature names\n",
    "features = list(train_test.columns) + ['sparse_' + vect_name for vect_name in c_vect_sparse1_cols]\n",
    "dtrain_data = pd.DataFrame(np.array(x_train.todense()), columns=features)\n",
    "dtest_data = pd.DataFrame(np.array(x_test.todense()), columns=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtrain_data.to_json('data/train.json', orient='records')\n",
    "dtest_data.to_json('data/test.json', orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
