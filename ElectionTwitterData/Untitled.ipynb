{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     /Users/jgzuke/nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n",
      "train on 1600 instances, test on 400 instances\n",
      "accuracy: 0.735\n",
      "Most Informative Features\n",
      "             outstanding = True              pos : neg    =     13.9 : 1.0\n",
      "               insulting = True              neg : pos    =     13.7 : 1.0\n",
      "              vulnerable = True              pos : neg    =     13.0 : 1.0\n",
      "               ludicrous = True              neg : pos    =     12.6 : 1.0\n",
      "             uninvolving = True              neg : pos    =     12.3 : 1.0\n",
      "                  avoids = True              pos : neg    =     11.7 : 1.0\n",
      "              astounding = True              pos : neg    =     11.7 : 1.0\n",
      "             fascination = True              pos : neg    =     11.0 : 1.0\n",
      "                    anna = True              pos : neg    =     10.3 : 1.0\n",
      "                  symbol = True              pos : neg    =     10.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "import nltk.classify.util\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "nltk.download('movie_reviews')\n",
    "from nltk.corpus import movie_reviews\n",
    " \n",
    "def word_feats(words):\n",
    "    return dict([(word, True) for word in words])\n",
    " \n",
    "negids = movie_reviews.fileids('neg')\n",
    "posids = movie_reviews.fileids('pos')\n",
    " \n",
    "negfeats = [(word_feats(movie_reviews.words(fileids=[f])), 'neg') for f in negids]\n",
    "posfeats = [(word_feats(movie_reviews.words(fileids=[f])), 'pos') for f in posids]\n",
    "\n",
    "trainfeats = negfeats[:800] + posfeats[:800]\n",
    "testfeats = negfeats[800:] + posfeats[800:]\n",
    "print ('train on %d instances, test on %d instances' % (len(trainfeats), len(testfeats)))\n",
    " \n",
    "classifier = NaiveBayesClassifier.train(trainfeats)\n",
    "print ('accuracy:', nltk.classify.util.accuracy(classifier, testfeats))\n",
    "classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['plot', ':', 'two', 'teen', 'couples', 'go', 'to', ...]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.words(fileids=[negids[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "tweets_raw = pd.read_csv(\"data/Sentiment.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 3672 instances, test on 800 instances\n",
      "accuracy: 0.71625\n",
      "Most Informative Features\n",
      "              gopdebates = True              pos : neg    =    337.0 : 1.0\n",
      "            rwsurfergirl = True              pos : neg    =     68.6 : 1.0\n",
      "                    band = True              pos : neg    =     48.3 : 1.0\n",
      "          donniewahlberg = True              pos : neg    =     37.7 : 1.0\n",
      "                   nails = True              pos : neg    =     33.0 : 1.0\n",
      "                together = True              pos : neg    =     29.8 : 1.0\n",
      "                 ratings = True              pos : neg    =     24.4 : 1.0\n",
      "                 tedcruz = True              pos : neg    =     22.1 : 1.0\n",
      "                  headed = True              pos : neg    =     21.0 : 1.0\n",
      "                 brought = True              pos : neg    =     19.7 : 1.0\n"
     ]
    }
   ],
   "source": [
    "sentiments = tweets_raw.loc[:,['sentiment', 'text']]\n",
    "sentiments_pos = sentiments[sentiments.sentiment == 'Positive']\n",
    "sentiments_neg = sentiments[sentiments.sentiment == 'Negative']\n",
    "\n",
    "import re\n",
    "def word_feats(tweet_full):\n",
    "    words = re.findall(r\"[\\w']+|[.,!?;]\", tweet_full[1])\n",
    "    words_filtered = [e.lower() for e in words if len(e) >= 3]\n",
    "    return dict([(word, True) for word in words_filtered])\n",
    "\n",
    "negfeats = [(word_feats(tweet_full), 'neg') for tweet_full in sentiments_neg.values]\n",
    "posfeats = [(word_feats(tweet_full), 'pos') for tweet_full in sentiments_pos.values]\n",
    "testfeats = negfeats[:400] + posfeats[:400]\n",
    "trainfeats = negfeats[400:2236] + posfeats[400:2236]\n",
    "print ('train on %d instances, test on %d instances' % (len(trainfeats), len(testfeats)))\n",
    " \n",
    "classifier = NaiveBayesClassifier.train(trainfeats)\n",
    "print ('accuracy:', nltk.classify.util.accuracy(classifier, testfeats))\n",
    "classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.71625\n"
     ]
    }
   ],
   "source": [
    "print ('accuracy:', nltk.classify.util.accuracy(classifier, testfeats))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reference_sets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-7acb64fa1300>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpos_precision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreference_sets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Positive'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_sets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Positive'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpos_recall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreference_sets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Positive'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_sets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Positive'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mneg_precision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreference_sets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Negative'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_sets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Negative'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'reference_sets' is not defined"
     ]
    }
   ],
   "source": [
    "from nltk.metrics.scores import precision\n",
    "from nltk.metrics.scores import recall\n",
    "pos_precision = nltk.precision(reference_sets['Positive'], test_sets['Positive'])\n",
    "pos_recall = nltk.recall(reference_sets['Positive'], test_sets['Positive'])\n",
    "neg_precision = nltk.precision(reference_sets['Negative'], test_sets['Negative'])\n",
    "neg_recall = nltk.recall(reference_sets['Negative'], test_sets['Negative'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
