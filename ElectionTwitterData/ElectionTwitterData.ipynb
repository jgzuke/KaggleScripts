{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 993,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk import NaiveBayesClassifier\n",
    "tweets_raw = pd.read_csv(\"data/Sentiment.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 994,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jgzuke/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "sentiments = tweets_raw.loc[:,['sentiment', 'text']]\n",
    "sentiments_pos = sentiments[sentiments.sentiment == 'Positive']\n",
    "sentiments_neg = sentiments[sentiments.sentiment == 'Negative']\n",
    "\n",
    "import re\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stopset = set(stopwords.words('english'))\n",
    "import itertools\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.metrics import BigramAssocMeasures\n",
    "\n",
    "pos_words = []\n",
    "neg_words = []\n",
    "\n",
    "def word_feats(tweet_full):\n",
    "    label = tweet_full[0]\n",
    "    words = re.findall(r\"[\\w']+|[.,!?;]\", tweet_full[1])\n",
    "    words_filtered = [e.lower() for e in words if (len(e) >= 3) & (e.lower() not in stopset)]\n",
    "    \n",
    "    if (label == 'Positive'):\n",
    "        pos_words.extend(words_filtered)\n",
    "    else:\n",
    "        neg_words.extend(words_filtered)\n",
    "    \n",
    "    bigram_finder = BigramCollocationFinder.from_words(words_filtered)\n",
    "    bigrams = bigram_finder.nbest(BigramAssocMeasures.chi_sq, 3)\n",
    "    return (dict([(ngram, True) for ngram in itertools.chain(words_filtered, bigrams)]), label)\n",
    "\n",
    "def word_feats_without_bigrams(tweet_full):\n",
    "    label = tweet_full[0]\n",
    "    words = re.findall(r\"[\\w']+|[.,!?;]\", tweet_full[1])\n",
    "    words_filtered = [e.lower() for e in words if (len(e) >= 3) & (e.lower() not in stopset)]\n",
    "    return (dict([(word, True) for word in words_filtered]), label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 995,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8493\n",
      "2236\n"
     ]
    }
   ],
   "source": [
    "neg_features = [word_feats(tweet_full) for tweet_full in sentiments_neg.values]\n",
    "pos_features = [word_feats(tweet_full) for tweet_full in sentiments_pos.values]\n",
    "sentiments_test = neg_features[:400] + pos_features[:400]\n",
    "sentiments_train = neg_features[400:] + pos_features[400:]\n",
    "print (len(neg_features))\n",
    "print (len(pos_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 996,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "from nltk.metrics.scores import precision\n",
    "from nltk.metrics.scores import recall\n",
    "def train_and_test(train, test):\n",
    "    clf = NaiveBayesClassifier.train(train)\n",
    "    print (clf.show_most_informative_features())\n",
    "    \n",
    "    reference_sets = collections.defaultdict(set)\n",
    "    test_sets = collections.defaultdict(set)\n",
    "    for i, features in enumerate(test):\n",
    "        label = features[1]\n",
    "        reference_sets[label].add(i)\n",
    "        predicted = clf.classify(features[0])\n",
    "        test_sets[predicted].add(i)\n",
    "\n",
    "    print (\"accuracy: \" + str(nltk.classify.util.accuracy(clf, sentiments_test)))\n",
    "    print (\"pos_precision: \" + str(nltk.precision(reference_sets['Positive'], test_sets['Positive'])))\n",
    "    print (\"pos_recall: \" + str(nltk.recall(reference_sets['Positive'], test_sets['Positive'])))\n",
    "    print (\"neg_precision: \" + str(nltk.precision(reference_sets['Negative'], test_sets['Negative'])))\n",
    "    print (\"neg_recall: \" + str(nltk.recall(reference_sets['Negative'], test_sets['Negative'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 997,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "          donniewahlberg = True           Positi : Negati =     99.6 : 1.0\n",
      "('brought', 'gopdebate') = True           Positi : Negati =     74.9 : 1.0\n",
      "               lrihendry = True           Positi : Negati =     73.9 : 1.0\n",
      "                libertyu = True           Positi : Negati =     54.3 : 1.0\n",
      "  ('candidates', \"i've\") = True           Positi : Negati =     54.3 : 1.0\n",
      "  ('favorite', 'things') = True           Positi : Negati =     54.3 : 1.0\n",
      "           wilberforce91 = True           Positi : Negati =     51.4 : 1.0\n",
      "            kimguilfoyle = True           Positi : Negati =     42.6 : 1.0\n",
      "                 forward = True           Positi : Negati =     40.2 : 1.0\n",
      "               favorites = True           Positi : Negati =     39.7 : 1.0\n",
      "None\n",
      "accuracy: 0.74875\n",
      "pos_precision: 0.7696476964769647\n",
      "pos_recall: 0.71\n",
      "neg_precision: 0.7308584686774942\n",
      "neg_recall: 0.7875\n"
     ]
    }
   ],
   "source": [
    "train_and_test(sentiments_train, sentiments_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 998,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "           ('and', 'am') = True           Positi : Negati =    174.8 : 1.0\n",
      "          donniewahlberg = True           Positi : Negati =     99.6 : 1.0\n",
      "       ('be', 'brought') = True           Positi : Negati =     74.9 : 1.0\n",
      "               lrihendry = True           Positi : Negati =     73.9 : 1.0\n",
      "         ('.', 'thanks') = True           Positi : Negati =     54.3 : 1.0\n",
      "                libertyu = True           Positi : Negati =     54.3 : 1.0\n",
      "           wilberforce91 = True           Positi : Negati =     51.4 : 1.0\n",
      "            kimguilfoyle = True           Positi : Negati =     42.6 : 1.0\n",
      "     ('as', 'president') = True           Positi : Negati =     41.3 : 1.0\n",
      "                 forward = True           Positi : Negati =     40.2 : 1.0\n",
      "None\n",
      "accuracy: 0.7925\n",
      "pos_precision: 0.8046875\n",
      "pos_recall: 0.7725\n",
      "neg_precision: 0.78125\n",
      "neg_recall: 0.8125\n"
     ]
    }
   ],
   "source": [
    "from nltk.probability import FreqDist, ConditionalFreqDist\n",
    "word_fd = FreqDist()\n",
    "label_word_fd = ConditionalFreqDist()\n",
    " \n",
    "for word in pos_words:\n",
    "    word_fd[word] += 1\n",
    "    label_word_fd['Positive'][word] += 1\n",
    "\n",
    "for word in neg_words:\n",
    "    word_fd[word] += 1\n",
    "    label_word_fd['Negative'][word] += 1\n",
    "\n",
    "pos_word_count = label_word_fd['Positive'].N()\n",
    "neg_word_count = label_word_fd['Negative'].N()\n",
    "total_word_count = pos_word_count + neg_word_count\n",
    " \n",
    "word_scores = {}\n",
    " \n",
    "for word in word_fd:\n",
    "    freq = word_fd[word]\n",
    "    pos_score = BigramAssocMeasures.chi_sq(label_word_fd['Positive'][word], (freq, pos_word_count), total_word_count)\n",
    "    neg_score = BigramAssocMeasures.chi_sq(label_word_fd['Negative'][word], (freq, neg_word_count), total_word_count)\n",
    "    word_scores[word] = pos_score + neg_score\n",
    "\n",
    "bestwords = sorted(word_scores, key=word_scores.get, reverse=True)[:2500]\n",
    "\n",
    "def best_word_feats(tweet_full):\n",
    "    label = tweet_full[0]\n",
    "    words = re.findall(r\"[\\w']+|[.,!?;]\", tweet_full[1])\n",
    "    words_all = [e.lower() for e in words]\n",
    "    words_filtered = [e for e in words_all if (len(e) >= 3) & (e not in stopset) & (e in bestwords)]\n",
    "    \n",
    "    if (label == 'Positive'):\n",
    "        pos_words.extend(words_filtered)\n",
    "    else:\n",
    "        neg_words.extend(words_filtered)\n",
    "    \n",
    "    bigram_finder = BigramCollocationFinder.from_words(words_all)\n",
    "    bigrams = bigram_finder.nbest(BigramAssocMeasures.chi_sq, 3)\n",
    "    return (dict([(ngram, True) for ngram in itertools.chain(words_filtered, bigrams)]), label)\n",
    "\n",
    "neg_features = [best_word_feats(tweet_full) for tweet_full in sentiments_neg.values]\n",
    "pos_features = [best_word_feats(tweet_full) for tweet_full in sentiments_pos.values]\n",
    "sentiments_test = neg_features[:400] + pos_features[:400]\n",
    "sentiments_train = neg_features[400:] + pos_features[400:]\n",
    "\n",
    "train_and_test(sentiments_train, sentiments_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
