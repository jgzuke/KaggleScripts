{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "tweets = pd.read_csv(\"data/Sentiment.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>candidate</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>subject_matter</th>\n",
       "      <th>name</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>No candidate mentioned</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>RaulAReyes</td>\n",
       "      <td>0</td>\n",
       "      <td>Going on #MSNBC Live with @ThomasARoberts arou...</td>\n",
       "      <td>2015-08-07 09:54:44 -0700</td>\n",
       "      <td>New York NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>Negative</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>jnjsmom</td>\n",
       "      <td>0</td>\n",
       "      <td>@JGreenDC @realDonaldTrump In all fairness #Bi...</td>\n",
       "      <td>2015-08-07 09:54:42 -0700</td>\n",
       "      <td>Peoria, IL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Scott Walker</td>\n",
       "      <td>Positive</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>In_Related_News</td>\n",
       "      <td>215</td>\n",
       "      <td>RT @pattonoswalt: I loved Scott Walker as Mark...</td>\n",
       "      <td>2015-08-07 09:54:42 -0700</td>\n",
       "      <td>San Diego, California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Ted Cruz</td>\n",
       "      <td>Positive</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>rickymcghee</td>\n",
       "      <td>6</td>\n",
       "      <td>RT @ChuckNellis: Cruz has class &amp;amp; truth, t...</td>\n",
       "      <td>2015-08-07 09:54:39 -0700</td>\n",
       "      <td>fripp island,sc/ southeast ga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Scott Walker</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Abortion</td>\n",
       "      <td>mch7576</td>\n",
       "      <td>19</td>\n",
       "      <td>RT @TheBaxterBean: Scott Walker's Abortion Ban...</td>\n",
       "      <td>2015-08-07 09:54:38 -0700</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 candidate sentiment     subject_matter             name  \\\n",
       "7   No candidate mentioned   Neutral  None of the above       RaulAReyes   \n",
       "10            Donald Trump  Negative  None of the above          jnjsmom   \n",
       "14            Scott Walker  Positive  None of the above  In_Related_News   \n",
       "20                Ted Cruz  Positive  None of the above      rickymcghee   \n",
       "26            Scott Walker  Negative           Abortion          mch7576   \n",
       "\n",
       "    retweet_count                                               text  \\\n",
       "7               0  Going on #MSNBC Live with @ThomasARoberts arou...   \n",
       "10              0  @JGreenDC @realDonaldTrump In all fairness #Bi...   \n",
       "14            215  RT @pattonoswalt: I loved Scott Walker as Mark...   \n",
       "20              6  RT @ChuckNellis: Cruz has class &amp; truth, t...   \n",
       "26             19  RT @TheBaxterBean: Scott Walker's Abortion Ban...   \n",
       "\n",
       "                tweet_created                 tweet_location  \n",
       "7   2015-08-07 09:54:44 -0700                    New York NY  \n",
       "10  2015-08-07 09:54:42 -0700                     Peoria, IL  \n",
       "14  2015-08-07 09:54:42 -0700          San Diego, California  \n",
       "20  2015-08-07 09:54:39 -0700  fripp island,sc/ southeast ga  \n",
       "26  2015-08-07 09:54:38 -0700                           USA   "
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_clean = tweets[(tweets.relevant_yn_confidence > 0.8) & (tweets.candidate_confidence > 0.8) & (tweets.sentiment_confidence > 0.8) & (tweets.subject_matter_confidence > 0.8)]\n",
    "tweets_clean = tweets_clean.drop(['id', 'candidate_confidence', 'relevant_yn', 'relevant_yn_confidence', 'sentiment_confidence', 'subject_matter_confidence', 'candidate_gold', 'relevant_yn_gold', 'sentiment_gold', 'subject_matter_gold', 'tweet_coord', 'tweet_id', 'user_timezone'], axis=1)\n",
    "tweets_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['candidate', 'sentiment', 'subject_matter', 'name', 'retweet_count',\n",
      "       'text', 'tweet_created', 'tweet_location'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print (tweets_clean.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "candidates = tweets_clean['candidate'].unique()\n",
    "candidates = [x for x in candidates if ((x != 'No candidate mentioned') & (len(tweets_clean[tweets_clean.candidate == x]) > 50))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>percent_positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Donald Trump</th>\n",
       "      <td>0.211091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scott Walker</th>\n",
       "      <td>0.123077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ted Cruz</th>\n",
       "      <td>0.695035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jeb Bush</th>\n",
       "      <td>0.028169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>John Kasich</th>\n",
       "      <td>0.76087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chris Christie</th>\n",
       "      <td>0.151515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ben Carson</th>\n",
       "      <td>0.640449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rand Paul</th>\n",
       "      <td>0.263158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mike Huckabee</th>\n",
       "      <td>0.314286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marco Rubio</th>\n",
       "      <td>0.565217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               percent_positive\n",
       "Donald Trump           0.211091\n",
       "Scott Walker           0.123077\n",
       "Ted Cruz               0.695035\n",
       "Jeb Bush               0.028169\n",
       "John Kasich             0.76087\n",
       "Chris Christie         0.151515\n",
       "Ben Carson             0.640449\n",
       "Rand Paul              0.263158\n",
       "Mike Huckabee          0.314286\n",
       "Marco Rubio            0.565217"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sb\n",
    "candidate_info = pd.DataFrame(columns=['percent_positive'], index=candidates)\n",
    "for candidate in candidates:\n",
    "    sentiments = tweets_clean[(tweets_clean.candidate == candidate)]['sentiment']\n",
    "    pos_count = len(sentiments[sentiments == 'Positive'])\n",
    "    neg_count = len(sentiments[sentiments == 'Negative'])\n",
    "    candidate_info.loc[candidate,'percent_positive'] = pos_count / (pos_count + neg_count)\n",
    "candidate_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentiments = tweets.loc[:,['sentiment', 'text']]\n",
    "sentiments = sentiments[sentiments.sentiment != 'Neutral']\n",
    "sentiments_test = sentiments[:1500]\n",
    "sentiments = sentiments[1500:]\n",
    "\n",
    "tweets_full = sentiments.values\n",
    "tweets = []\n",
    "for tweet_full in tweets_full:\n",
    "    words_filtered = [e.lower() for e in tweet_full[1].split() if len(e) >= 3]\n",
    "    tweets.append((words_filtered, tweet_full[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import NaiveBayesClassifier\n",
    "all_words = []\n",
    "for (words, label) in tweets:\n",
    "    all_words.extend(words)\n",
    "word_frequency = nltk.FreqDist(all_words)\n",
    "word_list = word_frequency.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def features(tweet):\n",
    "    tweet_words = set(tweet)\n",
    "    features = {}\n",
    "    for word in word_list:\n",
    "        features['contains(%s)' % word] = (word in tweet_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_set = nltk.classify.apply_features(features, tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = NaiveBayesClassifier.train(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "         contains(next.) = True           Positi : Negati =    154.7 : 1.0\n",
      "contains(@donniewahlberg:) = True           Positi : Negati =    139.4 : 1.0\n",
      "   contains(@lrihendry:) = True           Positi : Negati =     82.7 : 1.0\n",
      "     contains(@libertyu) = True           Positi : Negati =     47.3 : 1.0\n",
      "contains(@wilberforce91:) = True           Positi : Negati =     44.7 : 1.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print (clf.show_most_informative_features(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets_full_test = sentiments_test.values\n",
    "tweets_test = []\n",
    "for tweet_full in tweets_full_test:\n",
    "    words_filtered = [e.lower() for e in tweet_full[1].split() if len(e) >= 3]\n",
    "    tweets_test.append((words_filtered, tweet_full[0]))\n",
    "    \n",
    "test_set = nltk.classify.apply_features(features, tweets_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "reference_sets = collections.defaultdict(set)\n",
    "test_sets = collections.defaultdict(set)\n",
    "for i, (features, label) in enumerate(test_set):\n",
    "    reference_sets[label].add(i)\n",
    "    predicted = classifier.classify(features)\n",
    "    test_sets[predicted].add(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'nltk.translate.metrics' has no attribute 'precision'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-382-1574914af38e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpos_precision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreferenceSets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Positive'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestSets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Positive'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpos_recall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreferenceSets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Positive'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestSets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Positive'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mneg_precision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreferenceSets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Negative'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestSets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Negative'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'nltk.translate.metrics' has no attribute 'precision'"
     ]
    }
   ],
   "source": [
    "import nltk.metrics\n",
    "accuracy = nltk.classify.util.accuracy(classifier, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.metrics.scores import precision\n",
    "from nltk.metrics.scores import recall\n",
    "pos_precision = nltk.precision(reference_sets['Positive'], test_sets['Positive'])\n",
    "pos_recall = nltk.recall(reference_sets['Positive'], test_sets['Positive'])\n",
    "neg_precision = nltk.precision(reference_sets['Negative'], test_sets['Negative'])\n",
    "neg_recall = nltk.recall(reference_sets['Negative'], test_sets['Negative'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7746666666666666\n",
      "pos_precision: 0.391304347826087\n",
      "pos_recall: 0.054878048780487805\n",
      "neg_precision: 0.7867950481430537\n",
      "neg_recall: 0.9761092150170648\n"
     ]
    }
   ],
   "source": [
    "print (\"accuracy: \" + str(accuracy))\n",
    "print (\"pos_precision: \" + str(pos_precision))\n",
    "print (\"pos_recall: \" + str(pos_recall))\n",
    "print (\"neg_precision: \" + str(neg_precision))\n",
    "print (\"neg_recall: \" + str(neg_recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
