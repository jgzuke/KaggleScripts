{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import beta\n",
    "from scipy.stats import chi2\n",
    "from scipy.stats import gamma\n",
    "from scipy.stats import triang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "types = ['ball', 'bike', 'blocks', 'book', 'coal', 'doll', 'gloves', 'horse', 'train']\n",
    "num_types = len(types)\n",
    "key_to_item = dict((key, index) for key, index in zip(types, range(len(types))))\n",
    "step = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def normal(x, mu, sigma):\n",
    "    if x > 0:\n",
    "        return norm.pdf(x, mu, sigma)\n",
    "    return norm.cdf(0, mu, sigma)\n",
    "\n",
    "weight_gen_map = {\n",
    "    'horse': lambda: max(0, np.random.normal(5,2,1)[0]),\n",
    "    'ball': lambda: max(0, 1 + np.random.normal(1,0.3,1)[0]),\n",
    "    'bike': lambda: max(0, np.random.normal(20,10,1)[0]),\n",
    "    'train': lambda: max(0, np.random.normal(10,5,1)[0]),\n",
    "    'coal': lambda: 47 * np.random.beta(0.5,0.5,1)[0],\n",
    "    'book': lambda: np.random.chisquare(2,1)[0],\n",
    "    'doll': lambda: np.random.gamma(5,1,1)[0],\n",
    "    'blocks': lambda: np.random.triangular(5,10,20,1)[0],\n",
    "    'gloves': lambda: 3.0 + np.random.rand(1)[0] if np.random.rand(1) < 0.3 else np.random.rand(1)[0]\n",
    "}\n",
    "\n",
    "distribution_map = {\n",
    "    'horse': lambda x: normal(x, *(5, 2)),\n",
    "    'ball': lambda x: normal(x - 1, *(2, 0.3)),\n",
    "    'bike': lambda x: normal(x, *(20,10)),\n",
    "    'train': lambda x: normal(x, *(10,5)),\n",
    "    'coal': lambda x: beta.pdf(x / 47 , 0.5, 0.5) / 47,\n",
    "    'book': lambda x: chi2.pdf(x, 2),\n",
    "    'doll': lambda x: (x**4) * np.exp(-x) / 25,\n",
    "    'blocks': lambda x: triang.pdf(x, c = 1.0/3, loc = 5, scale = 15),\n",
    "    'gloves': lambda x: 0.7 if (0 < x and x < 1) else 0.3 if (3 < x and x < 4) else 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def save_expected_weights():\n",
    "    expected_weight_list = [list(key) + [expected_weight_map[key]] for key in expected_weight_map]\n",
    "    pd.DataFrame(expected_weight_list).to_csv('data/expected_weights', index=False)\n",
    "\n",
    "def load_expected_weights():\n",
    "    expected_weight_list = pd.read_csv('data/expected_weights')\n",
    "    return dict([(tuple(int(val) for val in row[:9]), row[9]) for row in expected_weight_list.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def bag_to_key(bag):\n",
    "    return tuple(bag)\n",
    "\n",
    "def item_to_key(item):\n",
    "    return tuple(1 if item == i else 0 for i in range(num_types))\n",
    "\n",
    "def item_to_full_item(item):\n",
    "    item_full = np.zeros((num_types,), dtype=np.int)\n",
    "    item_full[item] += 1\n",
    "    return item_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_expected(bag):\n",
    "    key = bag_to_key(bag)\n",
    "    if key in expected_weight_map:\n",
    "        return expected_weight_map[key]\n",
    "    expected_weight = sum(prob * weight for prob, weight in zip(weight_map[key], weight_slices))\n",
    "    expected_weight_map[key] = expected_weight\n",
    "    return expected_weight\n",
    "\n",
    "variance_reduce = 0.3\n",
    "def get_expected_high_variance(bag):\n",
    "    key = bag_to_key(bag)\n",
    "    if key in expected_weight_map:\n",
    "        return expected_weight_map[key]\n",
    "    expected_weight = sum(prob * weight for prob, weight in zip(weight_map[key], weight_slices))\n",
    "    chance_under = sum(weight_map[key])\n",
    "    expected_weight /= (chance_under ** variance_reduce)\n",
    "    expected_weight_map[key] = expected_weight\n",
    "    return expected_weight\n",
    "\n",
    "def get_chance_too_full(bag):\n",
    "    key = bag_to_key(bag)\n",
    "    if key in chance_too_full_map:\n",
    "        return chance_too_full_map[key]\n",
    "    chance_too_full = sum(weight_map[key])\n",
    "    chance_too_full_map[key] = chance_too_full\n",
    "    return 1 - chance_too_full\n",
    "\n",
    "def calculate_combined_distribution(old_bag, item):\n",
    "    bag = old_bag.copy()\n",
    "    bag[item] += 1\n",
    "    key = bag_to_key(bag)\n",
    "    # already caculated\n",
    "    if key in weight_map:\n",
    "        return None\n",
    "    \n",
    "    distribution = np.zeros((500,), dtype=np.float)\n",
    "    d1 = weight_map[bag_to_key(old_bag)]\n",
    "    d2 = weight_array_singles[item]\n",
    "    for p1, w1 in zip(d1, weight_indices):\n",
    "        for p2, w2 in zip(d2, weight_indices):\n",
    "            new_weight = w1 + w2\n",
    "            if new_weight < 500:\n",
    "                distribution[new_weight] += (p1 * p2)\n",
    "    weight_map[key] = distribution\n",
    "    return bag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODOS\n",
    "- figure out how to do add_weights beter given that step/2 + step/2 isnt 3/2 step\n",
    "- try increasing variance by increasing expected value if high chance of going over (multiply expected by (1/chance_under)^(0.5))\n",
    "- iteratively try different subset swaps\n",
    "- actually submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# use this to populate map with combinations\n",
    "# TODO make this faster and lower trial area\n",
    "def hydrate_map(iterations=10):\n",
    "    last_bags = [np.array([0, 0, 0, 0, 0, 0, 0, 0, 0])]\n",
    "    new_bags = []\n",
    "    for i in range(iterations):\n",
    "        for bag in last_bags:\n",
    "            expected = get_expected(bag)\n",
    "            for j in range(num_types):\n",
    "                new_bag = calculate_combined_distribution(bag, j)\n",
    "                if new_bag != None and get_expected(new_bag) > expected:\n",
    "                    new_bags.append(new_bag)\n",
    "        last_bags = new_bags\n",
    "        new_bags = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight_map = {tuple([0] * num_types): np.zeros((500,), dtype=np.float)}\n",
    "weight_map[tuple([0] * num_types)][0] = 1\n",
    "expected_weight_map = {tuple([0] * num_types): 0}\n",
    "chance_too_full_map = {tuple([0] * num_types): 0}\n",
    "\n",
    "weight_slices = np.arange(step / 2, 50, step)\n",
    "weight_indices = list(range(500))\n",
    "weight_array_singles = [np.array([step * distribution_map[key](weight) for weight in weight_slices]) for key in types]\n",
    "for weight_single in weight_array_singles:\n",
    "    total_prob = sum(weight_single)\n",
    "    for i in range(len(weight_single)):\n",
    "        weight_single[i] /= total_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jgzuke/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:11: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116168\n",
      "CPU times: user 2h 34min 9s, sys: 33 s, total: 2h 34min 42s\n",
      "Wall time: 2h 39min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "hydrate_map(50)\n",
    "print (len(weight_map))\n",
    "#save_expected_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#expected_weight_map = load_expected_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "useable_bags = [[np.array(key), expected_weight_map[key]] for key in expected_weight_map if sum(key) > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def accumulate(rows):\n",
    "    counts = np.array([0] * num_types)\n",
    "    score = 0\n",
    "    for row in rows:\n",
    "        counts += np.array(row[0])\n",
    "        score += row[1]\n",
    "    print (len(rows))\n",
    "    print (counts)\n",
    "    print (np.array([1100, 500, 1000, 1200, 166, 1000, 200, 1000, 1000]) - counts)\n",
    "    print (score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add normally as same in test_usefullness\n",
    "# iteratively\n",
    "    # remove some subset of elements and add in other possible combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_usefullness(usefulness, semi_sorted):\n",
    "    sorted_normalized = sorted(semi_sorted, key=lambda row: row[1] - sum(float(item) * factor for item, factor in zip(row[0], usefulness)))\n",
    "    sorted_normalized.reverse()\n",
    "\n",
    "    items_left = np.array([1100, 500, 1000, 1200, 166, 1000, 200, 1000, 1000])\n",
    "    score = 0\n",
    "    items = 0\n",
    "    bag_counts = []\n",
    "    for bag, bag_score in sorted_normalized:\n",
    "        num_of_item = 0\n",
    "        while items < 1000 and sum(item < 0 for item in (items_left - bag)) == 0:\n",
    "            items_left -= bag\n",
    "            score += bag_score\n",
    "            items += 1\n",
    "            num_of_item += 1\n",
    "        \n",
    "        if num_of_item > 0:\n",
    "            bag_counts.append((num_of_item, (bag, expected_weight_map[tuple(bag)])))\n",
    "            #bag_counts.append((num_of_item, bag))\n",
    "        \n",
    "        if items == 1000:\n",
    "            break\n",
    "\n",
    "    return (score, bag_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8, 0, 2.3, 2.0, 0, 1.05, 0.5, 1.2, 0.8]\n",
      "35574.3688132\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-132-eee59cbec39a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m                     \u001b[0musefulness\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mjitter1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                     \u001b[0musefulness\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mjitter2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                     \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbag_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_usefullness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musefulness\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_normalized_base\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                         \u001b[0mbest_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-111-87a1d11033dc>\u001b[0m in \u001b[0;36mtest_usefullness\u001b[0;34m(usefulness, semi_sorted)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_usefullness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musefulness\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msemi_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0msorted_normalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msemi_sorted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfactor\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musefulness\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0msorted_normalized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mitems_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m166\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-111-87a1d11033dc>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_usefullness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musefulness\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msemi_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0msorted_normalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msemi_sorted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfactor\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musefulness\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0msorted_normalized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mitems_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m166\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-111-87a1d11033dc>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_usefullness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musefulness\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msemi_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0msorted_normalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msemi_sorted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfactor\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musefulness\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0msorted_normalized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mitems_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m166\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "usefulness_base = [0.8, 0, 2.3, 2.0, 0, 1.05, 0.5, 1.2, 0.8]\n",
    "jitters = [0, 0.05, 0.1, 0.2]\n",
    "\n",
    "for i in range(10):\n",
    "    best_usefulness = None\n",
    "    best_score = 0\n",
    "    sorted_normalized_base = sorted(useable_bags, key=lambda row: row[1] - sum(float(item) * factor for item, factor in zip(row[0], usefulness_base)))\n",
    "    sorted_normalized_base.reverse()\n",
    "    sorted_normalized_base = sorted_normalized_base[:50000]\n",
    "    for j in range(len(usefulness_base)):\n",
    "        for k in range(j, len(usefulness_base)):\n",
    "            for jitter1 in jitters:\n",
    "                for jitter2 in jitters:\n",
    "                    usefulness = usefulness_base.copy()\n",
    "                    usefulness[j] += jitter1\n",
    "                    usefulness[k] += jitter2\n",
    "                    score, bag_counts = test_usefullness(usefulness, sorted_normalized_base)\n",
    "                    if score > best_score:\n",
    "                        best_score = score\n",
    "                        best_usefulness = usefulness\n",
    "\n",
    "    print (best_usefulness)\n",
    "    print (best_score)\n",
    "    usefulness_base = best_usefulness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score_bag(bag_counts):\n",
    "    assert (sum(count for count, bag in bag_counts) == 1000)\n",
    "    score_sum = 0\n",
    "    for count, bag in bag_counts:\n",
    "        for i in range(count):\n",
    "            weight = sum(weight_gen_map[item_type]() for item_type, item_num in zip(types, bag) for j in range(item_num))\n",
    "            if weight > 50:\n",
    "                continue\n",
    "            score_sum += weight\n",
    "    return score_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35574.3688132\n"
     ]
    }
   ],
   "source": [
    "usefulness = [0.8, 0, 2.3, 2.0, 0, 1.05, 0.5, 1.2, 0.8]\n",
    "score, bag_counts = test_usefullness(usefulness, useable_bags)\n",
    "#print (max(score_bag(bag_counts) for i in range(10)))\n",
    "print (score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(68, (array([16,  0,  0,  0,  0,  0,  0,  0,  0]), 46.69832242138849)),\n",
       " (1, (array([11,  0,  0,  0,  0,  0,  0,  2,  0]), 42.180295486424562)),\n",
       " (333, (array([0, 0, 0, 0, 0, 1, 0, 0, 3]), 33.05762270341819)),\n",
       " (333, (array([0, 0, 3, 0, 0, 0, 0, 1, 0]), 37.590305116183387)),\n",
       " (1, (array([1, 0, 1, 0, 0, 0, 0, 5, 0]), 38.08393658515736)),\n",
       " (1, (array([0, 1, 0, 0, 0, 1, 0, 0, 1]), 30.398699664499279)),\n",
       " (82, (array([0, 0, 0, 0, 0, 0, 0, 8, 0]), 38.088429484764525)),\n",
       " (1, (array([0, 0, 0, 0, 0, 4, 0, 4, 0]), 37.239938843658067)),\n",
       " (82, (array([0, 0, 0, 0, 0, 8, 0, 0, 0]), 36.518449093987364)),\n",
       " (2, (array([0, 1, 0, 0, 0, 3, 0, 0, 0]), 30.982752179742899)),\n",
       " (22, (array([0, 1, 0, 0, 0, 0, 9, 0, 0]), 29.924870417867957)),\n",
       " (2, (array([0, 2, 0, 0, 0, 0, 1, 0, 0]), 25.872064396729197)),\n",
       " (72, (array([0, 2, 0, 1, 0, 0, 0, 0, 0]), 25.491655947877572))]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "usefulness = [1.0, 0, 2.0, 2.0, 0.7, 0.95, 1.0, 1.2, 0.8]\n",
    "sorted_normalized = sorted(expected_weight_map, key=lambda key: normalize(key, usefulness) )\n",
    "sorted_normalized.reverse()\n",
    "[(a, expected_weight_map[a]) for a in sorted_normalized][:20]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
