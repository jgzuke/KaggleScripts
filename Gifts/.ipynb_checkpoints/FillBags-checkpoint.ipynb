{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "types = ['ball', 'bike', 'blocks', 'book', 'doll', 'horse', 'train']\n",
    "#types = ['ball', 'bike', 'blocks', 'book', 'coal', 'doll', 'gloves', 'horse', 'train']\n",
    "num_types = len(types)\n",
    "key_to_item = dict((key, index) for key, index in zip(types, range(len(types))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weight_gen_map = {\n",
    "    'horse': lambda: max(0, np.random.normal(5,2,1)[0]),\n",
    "    'ball': lambda: max(0, 1 + np.random.normal(1,0.3,1)[0]),\n",
    "    'bike': lambda: max(0, np.random.normal(20,10,1)[0]),\n",
    "    'train': lambda: max(0, np.random.normal(10,5,1)[0]),\n",
    "    'coal': lambda: 47 * np.random.beta(0.5,0.5,1)[0],\n",
    "    'book': lambda: np.random.chisquare(2,1)[0],\n",
    "    'doll': lambda: np.random.gamma(5,1,1)[0],\n",
    "    'blocks': lambda: np.random.triangular(5,10,20,1)[0],\n",
    "    'gloves': lambda: 3.0 + np.random.rand(1)[0] if np.random.rand(1) < 0.3 else np.random.rand(1)[0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "step = 0.2\n",
    "def normal_above_zero(x, mu, sigma):\n",
    "    return 1 / (sigma * np.sqrt(2 * np.pi)) * np.exp(-(x - mu)**2 / (2 * sigma**2))\n",
    "\n",
    "def normal(x, mu, sigma):\n",
    "    if x > 0:\n",
    "        return normal_above_zero(x, mu, sigma)\n",
    "    return sum(normal_above_zero(new_x, mu, sigma) * 0.05 for new_x in np.arange(-30, step / 2, 0.05))\n",
    "\n",
    "distribution_map = {\n",
    "    'horse': lambda x: normal(x, *(5, 2)),\n",
    "    'ball': lambda x: normal(x, *(2, 0.3)),\n",
    "    'bike': lambda x: normal(x, *(20,10)),\n",
    "    'train': lambda x: normal(x, *(10,5)),\n",
    "    'coal': lambda x: ((x + (step / 2)) / 47)**(-0.5) * (1 - ((x - (step / 2)) / 47))**(-0.5) / (47 * np.pi) if x <= 47 else 0,\n",
    "    'book': lambda x: np.exp(-(x / 2)) / 2,\n",
    "    'doll': lambda x: (x**4) * np.exp(-x) / 25,\n",
    "    'blocks': lambda x: (2 * (x - 5) / 75) if (5 < x and x <= 10) else (2 * (20 - x) / 150) if (10 < x and x < 20) else 0,\n",
    "    'gloves': lambda x: 0.7 if (0 < x and x < 1) else 0.3 if (3 < x and x < 4) else 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#weight_map = {}\n",
    "#expected_weight_map = {(0,0,0,0,0,0,0): 0}\n",
    "#chance_too_full_map = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def bag_to_key(bag):\n",
    "    return tuple(bag)\n",
    "\n",
    "def item_to_key(item):\n",
    "    return tuple(1 if item == i else 0 for i in range(num_types))\n",
    "\n",
    "def item_to_full_item(item):\n",
    "    item_full = np.zeros((num_types,), dtype=np.int)\n",
    "    item_full[item] += 1\n",
    "    return item_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weight_slices = np.arange(0, 50 + step, step)\n",
    "weight_indices = list(range(251))\n",
    "for key in types:\n",
    "    probs = [step * distribution_map[key](weight) for weight in weight_slices]\n",
    "    weight_map[item_to_key(key_to_item[key])] = probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_expected(old_bag, item=-1):\n",
    "    if item != -1:\n",
    "        bag = old_bag.copy()\n",
    "        bag[item] += 1\n",
    "    else:\n",
    "        bag = old_bag\n",
    "\n",
    "    key = bag_to_key(bag)\n",
    "    if key in expected_weight_map:\n",
    "        return expected_weight_map[key]\n",
    "    expected_weight = sum(prob * weight for prob, weight in zip(weight_map[key], weight_slices))\n",
    "    expected_weight_map[key] = expected_weight\n",
    "    return expected_weight\n",
    "\n",
    "def get_chance_too_full(bag):\n",
    "    key = bag_to_key(bag)\n",
    "    if key in chance_too_full_map:\n",
    "        return chance_too_full_map[key]\n",
    "    chance_too_full = sum(weight_map[key])\n",
    "    chance_too_full_map[key] = chance_too_full\n",
    "    return 1 - chance_too_full\n",
    "\n",
    "def get_combined_distribution(old_bag, item):\n",
    "    bag = old_bag.copy()\n",
    "    bag[item] += 1\n",
    "    key = bag_to_key(bag)\n",
    "    # already caculated\n",
    "    if key in weight_map:\n",
    "        return weight_map[key]\n",
    "    \n",
    "    distribution = np.zeros((251,), dtype=np.float)\n",
    "    d1 = weight_map[bag_to_key(old_bag)]\n",
    "    d2 = weight_map[item_to_key(item)]\n",
    "    for p1, w1 in zip(d1, weight_indices):\n",
    "        for p2, w2 in zip(d2, weight_indices):\n",
    "            new_weight = w1 + w2\n",
    "            if new_weight < 251:\n",
    "                distribution[new_weight] += (p1 * p2)\n",
    "    weight_map[key] = distribution\n",
    "    return distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for key in types:\n",
    "    expected_weight_map[item_to_key(key_to_item[key])] = get_expected(item_to_full_item(key_to_item[key]))\n",
    "    chance_too_full_map[item_to_key(key_to_item[key])] = get_chance_too_full(item_to_full_item(key_to_item[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 0, 0, 0, 0, 0, 1): 0.019129993354962904,\n",
       " (0, 0, 0, 0, 0, 1, 0): 0.0057431028396752737,\n",
       " (0, 0, 0, 0, 1, 0, 0): 0.039999989912123946,\n",
       " (0, 0, 0, 1, 0, 0, 0): -0.05083319446430079,\n",
       " (0, 0, 1, 0, 0, 0, 0): -2.2204460492503131e-16,\n",
       " (0, 1, 0, 0, 0, 0, 0): 0.019968120523329302,\n",
       " (1, 0, 0, 0, 0, 0, 0): 4.6697867794875947e-11,\n",
       " (2, 0, 1, 0, 0, 0, 0): 0.99999999990660415,\n",
       " (2, 2, 1, 0, 0, 0, 0): 0.31512791409696361}"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chance_too_full_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODOS\n",
    "- make fill_bags faster by \n",
    "    - add method to give chance of going over\n",
    "    - for all values with a certain chance of going over add it plus given item to expected_map\n",
    "- try increasing variance by increasing expected value if high chance of going over (multiply expected by (1/chance_under)^(0.5))\n",
    "- iteratively try different subset swaps\n",
    "- actually submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5593"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(expected_weight_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# use this to populate map with combinations\n",
    "# TODO make this faster and lower trial area\n",
    "\n",
    "def hydrate_map():\n",
    "    for i in range(1):\n",
    "        #gifts = pd.read_csv('data/gifts.csv').values\n",
    "        #counts = dict((name, 0) for name in types)\n",
    "        #for item in gifts:\n",
    "        #    key = item[0].split('_')[0]\n",
    "        #    if key in counts:\n",
    "        #        counts[key] += 1\n",
    "        #counts = [counts[key] for key in types]\n",
    "        counts = [1100, 500, 1000, 1200, 1000, 1000, 1000]\n",
    "        bags = np.zeros((num_bags, num_types), dtype=np.int)\n",
    "        \n",
    "        gifts = [gift for count, item in zip(counts, range(len(counts))) for gift in [item] * count]\n",
    "        np.random.shuffle(gifts)\n",
    "        for item in gifts:\n",
    "            for bag in bags:\n",
    "                expected = get_expected(bag)\n",
    "\n",
    "                distribution = get_combined_distribution(bag, item)\n",
    "                new_expected = get_expected(bag, item)\n",
    "\n",
    "                if new_expected > expected:\n",
    "                    if counts[item] > 0:\n",
    "                        bag[item] += 1\n",
    "                        counts[item] -= 1\n",
    "                        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36.7 s, sys: 111 ms, total: 36.8 s\n",
      "Wall time: 37 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "hydrate_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def normalize(key, usefulness):\n",
    "    return expected_weight_map[key] - sum(float(item) * factor for item, factor in zip(key, usefulness))\n",
    "\n",
    "def accumulate(rows):\n",
    "    counts = np.array([0, 0, 0, 0, 0, 0, 0])\n",
    "    score = 0\n",
    "    for row in rows:\n",
    "        counts += np.array(row[0])\n",
    "        score += row[1]\n",
    "    print (len(rows))\n",
    "    print (counts)\n",
    "    print (np.array([1100, 500, 1000, 1200, 1000, 1000, 1000]) - counts)\n",
    "    print (score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add normally as same in test_usefullness\n",
    "# iteratively\n",
    "    # remove some subset of elements and add in other possible combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_usefullness(usefulness):\n",
    "    sorted_normalized = sorted(expected_weight_map, key=lambda key: normalize(key, usefulness) )\n",
    "    sorted_normalized.reverse()\n",
    "\n",
    "    items_left = np.array([1100, 500, 1000, 1200, 1000, 1000, 1000])\n",
    "    score = 0\n",
    "    items = 0\n",
    "    bag_counts = []\n",
    "    for row in sorted_normalized:\n",
    "        num_of_item = 0\n",
    "        while items < 1000 and sum(item < 0 for item in (items_left - np.array(row))) == 0:\n",
    "            items_left -= np.array(row)\n",
    "            score += expected_weight_map[row]\n",
    "            items += 1\n",
    "            num_of_item += 1\n",
    "        \n",
    "        if num_of_item > 0:\n",
    "            #bag_counts.append((num_of_item, (row, expected_weight_map[row])))\n",
    "            bag_counts.append((num_of_item, row))\n",
    "        \n",
    "        if items == 1000:\n",
    "            break\n",
    "\n",
    "    return (score, bag_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "usefulness_base = [0.5, -1.7, 1.3, 1.45, -0.15, 0.55, -0.5]\n",
    "jitters = [0, -0.05, 0.05, 0.1, -0.1]\n",
    "\n",
    "for i in range(4):\n",
    "    best_usefulness = None\n",
    "    best_score = 0\n",
    "    for j in range(len(usefulness_base)):\n",
    "        for k in range(j, len(usefulness_base)):\n",
    "            for m in range(k, len(usefulness_base)):\n",
    "                for jitter1 in jitters:\n",
    "                    for jitter2 in jitters:\n",
    "                        for jitter3 in jitters:\n",
    "                            usefulness = usefulness_base.copy()\n",
    "                            usefulness[j] += jitter1\n",
    "                            usefulness[k] += jitter2\n",
    "                            usefulness[m] += jitter3\n",
    "                            score, bag_counts = test_usefullness(usefulness)\n",
    "                            if score > best_score:\n",
    "                                best_score = score\n",
    "                                best_usefulness = usefulness\n",
    "\n",
    "    print (best_usefulness)\n",
    "    print (best_score)\n",
    "    usefulness_base = best_usefulness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score_bag(bag_counts):\n",
    "    assert (sum(count for count, bag in bag_counts) == 1000)\n",
    "    score_sum = 0\n",
    "    for count, bag in bag_counts:\n",
    "        for i in range(count):\n",
    "            weight = sum(weight_gen_map[item_type]() for item_type, item_num in zip(types, bag) for j in range(item_num))\n",
    "            if weight > 50:\n",
    "                continue\n",
    "            score_sum += weight\n",
    "    return score_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35511.3842311\n",
      "35829.9351545\n"
     ]
    }
   ],
   "source": [
    "score, bag_counts = test_usefullness([0.5, -1.7, 1.3, 1.45, -0.15, 0.55, -0.5])\n",
    "print (max(score_bag(bag_counts) for i in range(10)))\n",
    "print (score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
