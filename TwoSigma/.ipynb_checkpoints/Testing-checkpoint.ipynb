{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jgzuke/anaconda3/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, BatchNormalization, LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.externals import joblib\n",
    "import kagglegym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_high_frequency_nan_distributions(data):\n",
    "    missing_values = {}\n",
    "    for row, row_id in zip(data.drop('y', 1).values, data['id'].values):\n",
    "        key = tuple([not math.isnan(val) for val in row])\n",
    "        if key in missing_values:\n",
    "            missing_values[key] += 1\n",
    "        else:\n",
    "            missing_values[key] = 1\n",
    "\n",
    "    high_frequency_nan_distributions = sorted([(key, missing_values[key]) for key in missing_values], key=lambda key_value: key_value[1])[-500:]\n",
    "    high_frequency_nan_distributions.reverse()\n",
    "    return high_frequency_nan_distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def filter_nan_distributions(cutoff, high_frequency_nan_distributions):\n",
    "    high_frequency_nan_distributions_filtered = []\n",
    "    for dist, count in high_frequency_nan_distributions:\n",
    "        new = min([sum(int(a != b) for a, b in zip(dist, dist2)) for dist2 in high_frequency_nan_distributions_filtered] + [len(dist)])\n",
    "        if (count * new * new) > cutoff:\n",
    "            high_frequency_nan_distributions_filtered.append(dist)\n",
    "    return np.array(high_frequency_nan_distributions_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_split_data(data):\n",
    "    has_y = 'y' in data.columns\n",
    "    data_to_use = data.drop('y', 1) if has_y else data\n",
    "    best_distribution = np.argmin([[6 * np.sum(np.logical_and(row, dist)) - np.sum(np.logical_or(row, dist)) for dist in nan_distributions] for row in data_to_use.isnull().values], axis=1)\n",
    "    nan_structures_split = [[best == i for best in best_distribution] for i in range(len(nan_distributions))]\n",
    "    column_splits = [[column for column, included in zip(list(data_to_use.columns), distribution) if included] + (['y'] if has_y else []) for distribution in nan_distributions]\n",
    "    return [data[split][columns] for split, distribution, columns in zip(nan_structures_split, nan_distributions, column_splits)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_and_test_model(model_generator, data_split_further):\n",
    "    clfs = []\n",
    "    total_samples = 0\n",
    "    total_score = 0.\n",
    "    for X_train, y_train, X_test, y_test in data_split_further:\n",
    "        X_train = X_train.fillna(0)\n",
    "        X_test = X_test.fillna(0)\n",
    "\n",
    "        clf = model_generator()\n",
    "        clf.fit(X_train.values, y_train.values)\n",
    "        #print ('Trained on {0}, Tested on {1}'.format(len(X_train), len(X_test)))\n",
    "        if len(X_test.values) > 0: \n",
    "            test_score = clf.score(X_test.values, y_test.values)\n",
    "            train_score = clf.score(X_train.values, y_train.values)\n",
    "            #print ('Test Score {0}, Training Score {1}'.format(test_score, train_score))\n",
    "            total_samples += len(X_test)\n",
    "            total_score += test_score * len(X_test)\n",
    "        clfs.append(clf)\n",
    "    #print ('Average Score ', total_score / total_samples)\n",
    "    return (clfs, total_score / total_samples)\n",
    "\n",
    "def train_model(model_generator, data_split):\n",
    "    clfs = []\n",
    "    for train in data_split:\n",
    "        X_train = train.drop('y', axis=1).fillna(0)\n",
    "        y_train = train['y']\n",
    "        clf = model_generator()\n",
    "        clf.fit(X_train.values, y_train.values)\n",
    "        clfs.append(clf)\n",
    "    return clfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 88.2 ms, sys: 726 ms, total: 815 ms\n",
      "Wall time: 1.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = pd.read_hdf('data/train.h5')\n",
    "cutoff = int(len(data) * 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "['                                                                                                              ', '    x x  xxx  xx x xxxx     xxx   xxxx  xx x x   xx xx xxx  xxx   x                                           ', '        x   x                   x           x                  x   x                                          ', '  xxxxx xxxxxxxx xxxxxxxxxx xxxxxxxxxxxxxxxxxxx  xxxxxxxxxx xxxxxxxx x                                        ', '  xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx xxxxxxxxx xxxxxxxxxx', '  xxxxx x x x  x  x    x  x x xxxxx  xx  x  x x      x x  x x  xx  x x        x               x               ']\n",
      "CPU times: user 37.3 s, sys: 860 ms, total: 38.1 s\n",
      "Wall time: 41.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# TODO dont use 40000, select number based on wanting 6 buckets\n",
    "high_frequency_nan_distributions = get_high_frequency_nan_distributions(data[:cutoff])\n",
    "nan_distributions = filter_nan_distributions(800000, high_frequency_nan_distributions)\n",
    "print (len(nan_distributions))\n",
    "print ([(''.join([' ' if val else 'x' for val in row])) for row in nan_distributions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_x_history(data):\n",
    "    X = []\n",
    "    y = []\n",
    "    X_columns = [item for item in data.columns if item not in ('id', 'timestamp', 'y')]\n",
    "    y_columns = ['y']\n",
    "    for item_id in np.unique(data.id):\n",
    "        data_for_id = data[data.id == item_id]\n",
    "        data_for_id_X = data_for_id[X_columns].values\n",
    "        data_for_id_y = data_for_id[y_columns].values\n",
    "        for i in range(len(data_for_id)):\n",
    "            X_to_use = data_for_id_X[max(i - samples_back_included, 0):i]\n",
    "            y_to_use = data_for_id_y[max(i - samples_back_included - 1, 0):max(i - 1, 0)]\n",
    "            if len(y_to_use) != 10 or len(X_to_use) != 10:\n",
    "                X_to_use = np.concatenate((np.full((10 - len(X_to_use), len(X_columns)), np.nan), X_to_use), axis=0)\n",
    "                y_to_use = np.concatenate((np.full((10 - len(y_to_use), len(y_columns)), np.nan), y_to_use), axis=0)\n",
    "            X.append(np.concatenate((X_to_use, y_to_use), axis=1))\n",
    "        y.extend(data_for_id.y.values)\n",
    "    return X, np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_x_history(data):\n",
    "    X = []\n",
    "    y = []\n",
    "    X_columns = [item for item in data.columns if item not in ('id', 'timestamp', 'y')]\n",
    "    y_columns = ['y']\n",
    "    for item_id in np.unique(data.id):\n",
    "        data_for_id = data[data.id == item_id]\n",
    "        data_for_id_X = data_for_id[X_columns].values\n",
    "        data_for_id_y = data_for_id[y_columns].values\n",
    "        for i in range(len(data_for_id)):\n",
    "            X_to_use = data_for_id_X[max(i - samples_back_included, 0):i]\n",
    "            y_to_use = data_for_id_y[max(i - samples_back_included - 1, 0):max(i - 1, 0)]\n",
    "            if len(y_to_use) != 10 or len(X_to_use) != 10:\n",
    "                X_to_use = np.concatenate((np.full((10 - len(X_to_use), len(X_columns)), np.nan), X_to_use), axis=0)\n",
    "                y_to_use = np.concatenate((np.full((10 - len(y_to_use), len(y_columns)), np.nan), y_to_use), axis=0)\n",
    "            X.append(np.concatenate((X_to_use, y_to_use), axis=1))\n",
    "        y.extend(data_for_id.y.values)\n",
    "    return X, np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samples_back_included = 10\n",
    "num_features = 109 # length of X + 1 extra for y\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_generator(data, timestamp_start, timestamp_end):\n",
    "    X = []\n",
    "    y = []\n",
    "    X_columns = [item for item in data.columns if item not in ('id', 'timestamp', 'y')]\n",
    "    y_columns = ['y']\n",
    "    X_empty_row = data[X_columns].mean().values\n",
    "    y_empty_row = data[y_columns].mean().values\n",
    "    for item_id in np.unique(data.id):\n",
    "        data_for_id = data[data.id == item_id]\n",
    "        data_for_id_X = data_for_id[X_columns].values\n",
    "        data_for_id_y = data_for_id[y_columns].values\n",
    "        data_for_id_timestamp = data_for_id['timestamp'].values\n",
    "        for i in range(len(data_for_id)):\n",
    "            if data_for_id_timestamp[i] < timestamp_start or data_for_id_timestamp[i] >= timestamp_end:\n",
    "                continue\n",
    "            X_to_use = data_for_id_X[max(i - samples_back_included, 0):i]\n",
    "            y_to_use = data_for_id_y[max(i - samples_back_included - 1, 0):max(i - 1, 0)]\n",
    "            if len(X_to_use) != 10:\n",
    "                X_to_use = np.concatenate((np.array([X_empty_row] * (10 - len(X_to_use))), X_to_use), axis=0)\n",
    "            if len(y_to_use) != 10:\n",
    "                y_to_use = np.concatenate((np.array([y_empty_row] * (10 - len(y_to_use))), y_to_use), axis=0)\n",
    "            X.append(np.concatenate((X_to_use, y_to_use), axis=1))\n",
    "            y.append(data_for_id_y[i])\n",
    "            if len(X) == batch_size:\n",
    "                yield (np.array(X), np.array(y))\n",
    "                X = []\n",
    "                y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "u=np.mean(real_y.y)\n",
    "dem=np.sum((real_y.y.values-u)**2)\n",
    "r2=1-tot/dem\n",
    "if r2<0:\n",
    "    print(-np.sqrt(-r2))\n",
    "else:\n",
    "    print(np.sqrt(r2))\n",
    "\n",
    "\n",
    "def r_score_old(y_true, y_pred, sample_weight=None, multioutput=None):\n",
    "    r2 = r2_score(y_true, y_pred, sample_weight=sample_weight,\n",
    "                  multioutput=multioutput)\n",
    "    r = (np.sign(r2)*np.sqrt(np.abs(r2)))\n",
    "    if r <= -1:\n",
    "        return -1\n",
    "    else:\n",
    "        return r\n",
    "    \n",
    "def r_score(y_true, y_pred):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, batch_input_shape=[batch_size, samples_back_included, num_features], stateful=True))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('softsign'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss=r_score,\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 523 ms, sys: 421 ms, total: 944 ms\n",
      "Wall time: 979 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = data.fillna(data.mean())\n",
    "#test_cutoff = int(len(data) / batch_size) * batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "160160/160160 [==============================] - 134s - loss: 9.7889e-04 - acc: 6.2438e-06   \n",
      "Epoch 2/8\n",
      "160160/160160 [==============================] - 134s - loss: 4.8701e-04 - acc: 2.4975e-05   \n",
      "Epoch 3/8\n",
      "160160/160160 [==============================] - 137s - loss: 4.1376e-04 - acc: 6.2438e-06   \n",
      "Epoch 4/8\n",
      "160160/160160 [==============================] - 137s - loss: 4.5303e-04 - acc: 6.2438e-06   \n",
      "Epoch 5/8\n",
      "160160/160160 [==============================] - 141s - loss: 4.0611e-04 - acc: 1.2488e-05   \n",
      "Epoch 6/8\n",
      "160160/160160 [==============================] - 145s - loss: 4.2294e-04 - acc: 6.2438e-06   \n",
      "Epoch 7/8\n",
      "160160/160160 [==============================] - 148s - loss: 3.6291e-04 - acc: 1.8731e-05   \n",
      "Epoch 8/8\n",
      "160160/160160 [==============================] - 148s - loss: 3.9600e-04 - acc: 1.2488e-05   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15158a898>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_bounds = (0, 1400)\n",
    "test_bounds = (1400, 1812) # 1812\n",
    "epochs = 8\n",
    "train_samples = int(len(data[(data.timestamp >= train_bounds[0]) & (data.timestamp < train_bounds[1])]) / batch_size / epochs) * batch_size - batch_size\n",
    "test_samples = int(len(data[(data.timestamp >= test_bounds[0]) & (data.timestamp < test_bounds[1])]) / batch_size) * batch_size - batch_size\n",
    "\n",
    "#model.fit_generator(data_generator(data, train_bounds[0], train_bounds[1]), samples_per_epoch=train_samples, nb_epoch=epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.00076241167835395781, 0.0]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_generator(data_generator(data, test_bounds[0], test_bounds[1]), val_samples=13374)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160160"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 4s, sys: 4.3 s, total: 2min 8s\n",
      "Wall time: 2min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_split_train = get_split_data(data[:cutoff])\n",
    "data_split_test = get_split_data(data[cutoff:])\n",
    "data_split_further = [[data_train.drop('y', axis=1), data_train[['id', 'timestamp', 'y']], data_test.drop('y', axis=1), data_test[]] for data_train, data_test in zip(data_split_train, data_split_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "et_clfs, score = train_and_test_model(lambda: ExtraTreesRegressor(n_estimators=25, max_depth=4, random_state=17, verbose=0), data_split_further)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = data_split_further[4]\n",
    "#X_train = X_train.fillna(0)\n",
    "#scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#X_train = scaler.fit_transform(X_train)\n",
    "#joblib.dump(scaler, 'data/models/scaler_{}.pkl'.format(0))\n",
    "\n",
    "#X_test = X_test.fillna(0)\n",
    "#X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samples_back_included = 10\n",
    "num_features = 111 # length of X + 1 extra for y\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "id_wanted = 10\n",
    "timestamp = 5\n",
    "X_to_use = X_train[(X_train.id == 10) & (X_train.timestamp < timestamp) & (X_train.timestamp > timestamp - samples_back_included)]\n",
    "y_to_use = y_train[(y_train.id == 10) & (y_train.timestamp < timestamp - 1) & (y_train.timestamp > timestamp - samples_back_included - 1)]\n",
    "\n",
    "#y_train[(y_train.id == 10) & (y_train.timestamp < 25) & (y_train.timestamp > 20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>technical_41</th>\n",
       "      <th>technical_42</th>\n",
       "      <th>technical_43</th>\n",
       "      <th>technical_44</th>\n",
       "      <th>technical_5</th>\n",
       "      <th>technical_6</th>\n",
       "      <th>technical_7</th>\n",
       "      <th>technical_9</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.011753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.005850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2250</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.000476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.005212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 222 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0   1   2   3   4   5   6   7   8   9    ...     technical_41  \\\n",
       "0    NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN    ...              NaN   \n",
       "1    NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN    ...              NaN   \n",
       "2    NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN    ...              NaN   \n",
       "3    NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN    ...              NaN   \n",
       "4    NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN    ...              NaN   \n",
       "0    NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN    ...              NaN   \n",
       "750  NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN    ...              NaN   \n",
       "1500 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN    ...              NaN   \n",
       "2250 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN    ...              NaN   \n",
       "3000 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN    ...              NaN   \n",
       "\n",
       "      technical_42  technical_43  technical_44  technical_5  technical_6  \\\n",
       "0              NaN           NaN           NaN          NaN          NaN   \n",
       "1              NaN           NaN           NaN          NaN          NaN   \n",
       "2              NaN           NaN           NaN          NaN          NaN   \n",
       "3              NaN           NaN           NaN          NaN          NaN   \n",
       "4              NaN           NaN           NaN          NaN          NaN   \n",
       "0              NaN           NaN           NaN          NaN          NaN   \n",
       "750            NaN           NaN           NaN          NaN          NaN   \n",
       "1500           NaN           NaN           NaN          NaN          NaN   \n",
       "2250           NaN           NaN           NaN          NaN          NaN   \n",
       "3000           NaN           NaN           NaN          NaN          NaN   \n",
       "\n",
       "      technical_7  technical_9  timestamp         y  \n",
       "0             NaN          NaN        NaN       NaN  \n",
       "1             NaN          NaN        NaN       NaN  \n",
       "2             NaN          NaN        NaN       NaN  \n",
       "3             NaN          NaN        NaN       NaN  \n",
       "4             NaN          NaN        NaN       NaN  \n",
       "0             NaN          NaN        0.0       NaN  \n",
       "750           NaN          NaN        1.0 -0.011753  \n",
       "1500          NaN          NaN        2.0  0.005850  \n",
       "2250          NaN          NaN        3.0 -0.000476  \n",
       "3000          NaN          NaN        4.0  0.005212  \n",
       "\n",
       "[10 rows x 222 columns]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_merged = pd.DataFrame(columns=columns)\n",
    "y_merged = pd.DataFrame(columns=['y', 'timestamp'])\n",
    "for X_train, y_train, X_test, y_test in data_split_further:\n",
    "    X_for_id = X_train[(X_train.id == 10) & (X_train.timestamp < timestamp) & (X_train.timestamp > timestamp - samples_back_included)]\n",
    "    y_for_id = y_train[(y_train.id == 10) & (y_train.timestamp < timestamp - 1) & (y_train.timestamp > timestamp - samples_back_included - 1)]\n",
    "    X_merged = X_merged.append(X_for_id)\n",
    "    y_merged = y_merged.append(y_for_id)\n",
    "\n",
    "X_merged = X_merged.sort_values(['timestamp'], ascending=[True])\n",
    "y_merged = y_merged.sort_values(['timestamp'], ascending=[True])\n",
    "\n",
    "X_merged = pd.DataFrame(np.full((10 - len(X_merged), len(columns)), np.nan)).append(X_merged)\n",
    "y_merged = pd.DataFrame(np.full((10 - len(y_merged), 2), np.nan)).append(y_merged)\n",
    "X_merged.y = y_merged['y'].values\n",
    "X_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 426 ms, sys: 2.84 s, total: 3.26 s\n",
      "Wall time: 6.12 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "env = kagglegym.make()\n",
    "observation = env.reset()\n",
    "data = observation.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 14s, sys: 1.1 s, total: 1min 15s\n",
      "Wall time: 1min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "high_frequency_nan_distributions = get_high_frequency_nan_distributions(data)\n",
    "nan_distributions = filter_nan_distributions(500000, high_frequency_nan_distributions)\n",
    "data_split = get_split_data(data)\n",
    "clfs = train_model(lambda: ExtraTreesRegressor(n_estimators=25, max_depth=4, random_state=17, verbose=0), data_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.11128681189\n",
      "0.0825276854025\n",
      "-0.0548432430466\n",
      "-0.15183885798\n",
      "-0.0923139783666\n",
      "-0.0825648098422\n",
      "-0.107279092471\n",
      "-0.0520323144763\n",
      "-0.360260755881\n",
      "-0.197959841749\n",
      "-0.0816455593487\n",
      "-0.133597131291\n",
      "-0.138718911415\n",
      "0.0298962237767\n",
      "-0.12717418969\n",
      "-0.114115171981\n",
      "-0.0943293327787\n",
      "-0.0396678680466\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-1672bff7944c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"n = 0\\nrewards = []\\nwhile True:\\n    target = observation.target\\n    features_split = get_split_data(observation.features)\\n    for X, clf in zip(features_split, et_clfs):\\n        X = X.fillna(0)\\n        y = clf.predict(X)\\n        for result_id, result in zip(X.id.values, y):\\n            target.loc[observation.target.id == result_id, 'y'] = result\\n    observation, reward, done, info = env.step(target)\\n    if done:\\n        break\\n    print (reward)\\n    rewards.append(reward)\\n    n = n + 1\\n\\nprint(info)\\nprint(n)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/jgzuke/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2113\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2114\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2115\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2116\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-59>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m/Users/jgzuke/anaconda3/lib/python3.5/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jgzuke/anaconda3/lib/python3.5/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1178\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/Users/jgzuke/anaconda3/lib/python3.5/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, other, axis)\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_values_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 769\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bool'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    770\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jgzuke/anaconda3/lib/python3.5/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    228\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSingleBlockManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0mgeneric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jgzuke/anaconda3/lib/python3.5/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, axes, copy, dtype, fastpath)\u001b[0m\n\u001b[1;32m    102\u001b[0m                     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'is_copy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_item_cache'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n = 0\n",
    "rewards = []\n",
    "while True:\n",
    "    target = observation.target\n",
    "    features_split = get_split_data(observation.features)\n",
    "    for X, clf in zip(features_split, clfs):\n",
    "        X = X.fillna(0)\n",
    "        y = clf.predict(X)\n",
    "        for result_id, result in zip(X.id.values, y):\n",
    "            target.loc[observation.target.id == result_id, 'y'] = result\n",
    "    observation, reward, done, info = env.step(target)\n",
    "    if done:\n",
    "        break\n",
    "    print (reward)\n",
    "    rewards.append(reward)\n",
    "    n = n + 1\n",
    "\n",
    "print(info)\n",
    "print(n)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
